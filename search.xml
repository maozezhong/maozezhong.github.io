<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hash表]]></title>
    <url>%2F2018%2F04%2F19%2Fhash%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希映射函数/* BKDR Hash Function */ unsigned int BKDR_hash(char *str) { unsigned int seed = 131; // 31 131 1313 13131 131313 etc.. unsigned int hash = 0; while (*str) { hash = hash * seed + (*str++); } return (hash &amp; 0x7FFFFFFF); } 哈希解决冲突开放定址法 线性探测再散列：顺序查看表中下一单元，直到找出一个空单元或查遍全表。 二次探测再散列：冲突发生时，在表的左右进行跳跃式探测，比较灵活 伪随机探测再散列：建立一个伪随机数发生器，（如i=(i+p) % m），并给定一个随机数做起点。 实例：已知哈希表长度m=11，哈希函数为：H（key）= key % 11，则H（47）=3，H（26）=4，H（60）=5，假设下一个关键字为69，则H（69）=3，与47冲突。1）如果用线性探测再散列处理冲突，下一个哈希地址为H1=（3 + 1）% 11 = 4，仍然冲突，再找下一个哈希地址为H2=（3 + 2）% 11 = 5，还是冲突，继续找下一个哈希地址为H3=（3 + 3）% 11 = 6，此时不再冲突，将69填入5号单元。 2）如果用二次探测再散列处理冲突，下一个哈希地址为H1=（3 + 12）% 11 = 4，仍然冲突，再找下一个哈希地址为H2=（3 - 12）% 11 = 2，此时不再冲突，将69填入2号单元。3）如果用伪随机探测再散列处理冲突，且伪随机数序列为：2，5，9，……..，则下一个哈希地址为H1=（3 + 2）% 11 = 5，仍然冲突，再找下一个哈希地址为H2=（3 + 5）% 11 = 8，此时不再冲突，将69填入8号单元。 再哈希法 同时构造多个不同的哈希函数，这种方法不易产生聚集，但增加了计算时间。 链地址法（拉链法） 基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。 建立公共溢出区 将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。 hash表代码c++/* 因为类的申明和定义分开来分别在.h和.cpp文件，我这边编译错误，所以放在了一起。 */ //--------simpleHashTable.h------- #pragma once #include &lt;iostream&gt; using namespace std; typedef int KeyType; #define NULLKEY -1 struct Entry{ KeyType _key; int _value; Entry(KeyType key=NULLKEY, int value=0):_key(key),_value(value){} }; class hashTable{ public: hashTable(); //hashTable(int tableSize); ~hashTable(); bool find(const Entry&amp; e); bool insert(const Entry&amp; e); bool remove(const Entry&amp; e); void clear(); Entry&amp; operator[](KeyType key);//重载下标操作；当找不到key对应的Entry时，插入Entry(key,0) int size(); void display(); protected: int hashFunction(KeyType key);//将键值映射到对应地址 void rehash();//调整hashTable大小 bool find(const KeyType&amp; k);//按键值查找 int nextPrime();//p(n) = n^2 - n + 41, n&lt;41, p&lt;1681 private: Entry *_pTable; int _pos;//当前访问元素的位置 int _size; int _capacity; int primeIndex; }; hashTable::hashTable() { _capacity = 3;//初始化hashTable容量为3,便于观察rehash过程 _pTable = new Entry[_capacity]; _size = 0; primeIndex = 1; } //hashTable::hashTable(int tableSize) //{ // //} hashTable::~hashTable() { clear(); } int hashTable::nextPrime() { int p = std::pow(static_cast&lt;float&gt;(primeIndex),2) - primeIndex + 41; primeIndex = primeIndex &lt;&lt; 1; if(primeIndex &gt;= 41){ cout &lt;&lt; &quot;Max capacity reached. exit!&quot; &lt;&lt; endl; exit(-1); } return p; } bool hashTable::find(const Entry&amp; e) { return(find(e._key)); } bool hashTable::find(const KeyType&amp; k) { _pos = hashFunction(k); if(_pTable[_pos]._key==NULLKEY) return false; int lastPos = _pos; while(_pTable[_pos]._key!=k){ if(++_pos%_capacity == lastPos) return false; } return true; } bool hashTable::insert(const Entry&amp; e) { if((_size*1.0)/_capacity&gt;0.75) rehash();//[OK]插入操作前，需要判断hash table是否需要扩容 if(find(e)) return false; _pTable[_pos] = e; ++_size; return true; } bool hashTable::remove(const Entry&amp; e) { if(!find(e)) return false; _pTable[_pos]._key = NULLKEY; --_size; //rehash();//移除操作后，需要判断hash table是否需要缩容 return true; } void hashTable::clear() { delete []_pTable; _size = _capacity = 0; } Entry&amp; hashTable::operator[](KeyType key) { if(!find(key)) insert(Entry(key,0)); return _pTable[_pos]; } int hashTable::size() { return _size; } int hashTable::hashFunction(KeyType key) { return key%_capacity; } void hashTable::display() { cout &lt;&lt; &quot;capacity = &quot; &lt;&lt; _capacity &lt;&lt; &quot;, size = &quot; &lt;&lt; _size &lt;&lt; endl; for(int i=0; i&lt;_capacity; i++){ if(_pTable[i]._key!=NULLKEY) cout &lt;&lt; &quot;key=&quot; &lt;&lt; _pTable[i]._key &lt;&lt; &quot;,value=&quot; &lt;&lt; _pTable[i]._value &lt;&lt; endl; } } void hashTable::rehash() { cout &lt;&lt; &quot;begin rehash...&quot; &lt;&lt; endl; Entry *p = new Entry[_size];//用来暂存原哈希表 for(int i=0; i&lt;_capacity; i++){//i&lt;_size不对；元素散列在容量为_capacity的hashTable中 if(_pTable[i]._key != NULLKEY) *(p+i) = _pTable[i]; } delete []_pTable; int lastSize = _size; _size = 0; _capacity = nextPrime(); _pTable = new Entry[_capacity]; for(int i=0; i&lt;lastSize; i++) insert(*(p+i)); delete []p; } //------testbench.cpp------ #include &lt;iostream&gt; #include &quot;simpleHashTable.h&quot; using namespace std; int main() { hashTable *pTable = new hashTable; cout &lt;&lt; &quot;insert Entry(1,11)...&quot; &lt;&lt; endl; pTable-&gt;insert(Entry(1,11)); pTable-&gt;display(); cout &lt;&lt; &quot;insert Entry(2,22)...&quot; &lt;&lt; endl; pTable-&gt;insert(Entry(2,22)); pTable-&gt;display(); cout &lt;&lt; &quot;insert Entry(3,33)...&quot; &lt;&lt; endl; pTable-&gt;insert(Entry(3,33)); pTable-&gt;display(); cout &lt;&lt; &quot;insert Entry(4,44)...&quot; &lt;&lt; endl; //pTable-&gt;insert(Entry(4,44)); (*pTable)[4]._value = 44;//下标操作，返回值充当左值 pTable-&gt;display(); cout &lt;&lt; endl &lt;&lt; &quot;delete Entry(1,11)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(1,11)); pTable-&gt;display(); cout &lt;&lt; &quot;delete Entry(2,22)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(2,22)); pTable-&gt;display(); cout &lt;&lt; &quot;delete Entry(3,33)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(3,33)); pTable-&gt;display(); cout &lt;&lt; &quot;delete Entry(3,33)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(3,33)); pTable-&gt;display(); delete pTable; getchar(); return 0; } c#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;time.h&gt; /*=================hash table start=========================================*/ #define HASH_TABLE_MAX_SIZE 10000 typedef struct HashNode_Struct HashNode; struct HashNode_Struct { char* sKey; int nValue; HashNode* pNext; }; HashNode* hashTable[HASH_TABLE_MAX_SIZE]; //hash table data strcutrue int hash_table_size; //the number of key-value pairs in the hash table! //initialize hash table void hash_table_init() { hash_table_size = 0; memset(hashTable, 0, sizeof(HashNode*) * HASH_TABLE_MAX_SIZE); } //string hash function unsigned int hash_table_hash_str(const char* skey) { const signed char *p = (const signed char*)skey; unsigned int h = *p; if(h) { for(p += 1; *p != &apos;\0&apos;; ++p) h = (h &lt;&lt; 5) - h + *p; //h = h*31+*p } return h; } //insert key-value into hash table void hash_table_insert(const char* skey, int nvalue) { if(hash_table_size &gt;= HASH_TABLE_MAX_SIZE) { printf(&quot;out of hash table memory!\n&quot;); return; } unsigned int pos = hash_table_hash_str(skey) % HASH_TABLE_MAX_SIZE; HashNode* pHead = hashTable[pos]; while(pHead) { if(strcmp(pHead-&gt;sKey, skey) == 0) //strcmp(str1, str2)：1）相等返回0；2）str1&lt;str2返回负数；3）str1&gt;str2返回正数 { printf(&quot;%s already exists!\n&quot;, skey); return ; } pHead = pHead-&gt;pNext; } HashNode* pNewNode = (HashNode*)malloc(sizeof(HashNode)); memset(pNewNode, 0, sizeof(HashNode)); pNewNode-&gt;sKey = (char*)malloc(sizeof(char) * (strlen(skey) + 1)); strcpy(pNewNode-&gt;sKey, skey); pNewNode-&gt;nValue = nvalue; pNewNode-&gt;pNext = hashTable[pos]; hashTable[pos] = pNewNode; hash_table_size++; } //remove key-value from the hash table void hash_table_remove(const char* skey) { unsigned int pos = hash_table_hash_str(skey) % HASH_TABLE_MAX_SIZE; if(hashTable[pos]) { HashNode* pHead = hashTable[pos]; HashNode* pLast = NULL; HashNode* pRemove = NULL; while(pHead) { if(strcmp(skey, pHead-&gt;sKey) == 0) { pRemove = pHead; break; } pLast = pHead; pHead = pHead-&gt;pNext; } if(pRemove) { if(pLast) pLast-&gt;pNext = pRemove-&gt;pNext; else hashTable[pos] = NULL; free(pRemove-&gt;sKey); free(pRemove); } } } //lookup a key in the hash table HashNode* hash_table_lookup(const char* skey) { unsigned int pos = hash_table_hash_str(skey) % HASH_TABLE_MAX_SIZE; if(hashTable[pos]) { HashNode* pHead = hashTable[pos]; while(pHead) { if(strcmp(skey, pHead-&gt;sKey) == 0) return pHead; pHead = pHead-&gt;pNext; } } return NULL; } //print the content in the hash table void hash_table_print() { printf(&quot;===========content of hash table=================\n&quot;); int i; for(i = 0; i &lt; HASH_TABLE_MAX_SIZE; ++i) if(hashTable[i]) { HashNode* pHead = hashTable[i]; printf(&quot;%d=&gt;&quot;, i); while(pHead) { printf(&quot;%s:%d &quot;, pHead-&gt;sKey, pHead-&gt;nValue); pHead = pHead-&gt;pNext; } printf(&quot;\n&quot;); } } //free the memory of the hash table void hash_table_release() { int i; for(i = 0; i &lt; HASH_TABLE_MAX_SIZE; ++i) { if(hashTable[i]) { HashNode* pHead = hashTable[i]; while(pHead) { HashNode* pTemp = pHead; pHead = pHead-&gt;pNext; if(pTemp) { free(pTemp-&gt;sKey); free(pTemp); } } } } } /* ===============================hash table end=========================*/ /* ============================test function ============================*/ #define MAX_STR_LEN 20 #define MIN_STR_LEN 10 void rand_str(char r[]) { int i; int len = MIN_STR_LEN + rand() % (MAX_STR_LEN - MIN_STR_LEN); for(i = 0; i &lt; len - 1; ++i) r[i] = &apos;a&apos; + rand() % ( &apos;z&apos; - &apos;a&apos;); r[len - 1] = &apos;\0&apos;; } int main(int argc, char** argv) { srand(time(NULL)); hash_table_init(); printf(&quot;insert testing.........\n&quot;); int n = 10; const char *key1 = &quot;aaammd&quot;; const char *key2 = &quot;xzzyym&quot;; const char *key3 = &quot;cdcded&quot;; hash_table_insert(key1, 110); hash_table_insert(key2, 220); hash_table_insert(key3, 330); char str[MAX_STR_LEN + 1]; while(n--) { rand_str(str); hash_table_insert(str, n); } hash_table_print(); printf(&quot;\nlookup testing..........\n&quot;); HashNode* pNode = hash_table_lookup(key1); printf(&quot;lookup result:%d\n&quot;, pNode-&gt;nValue); pNode = hash_table_lookup(key2); printf(&quot;lookup result:%d\n&quot;, pNode-&gt;nValue); printf(&quot;\nremove testing..........\n&quot;); printf(&quot;before remove %s:\n&quot;, key3); hash_table_print(); hash_table_remove(key3); printf(&quot;after remove:\n&quot;); hash_table_print(); hash_table_release(); system(&quot;pause&quot;); return 0; } 参考链接 数据结构与算法：hash冲突解决 hash算法的数学原理是什么，如何保证尽可能少的碰撞？ C++简单实现hash table C++模板中声明和定义是否可以分开存放在.h和.cpp文件中 C++模板类头文件和实现文件分离的方法 C++ 中的模板类声明头文件和实现文件分离后，如何能实现正常编译？]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow实现softmax分类]]></title>
    <url>%2F2018%2F04%2F15%2Ftensorflow%E5%AE%9E%E7%8E%B0softmax%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[使用tensorflow实现softmax分类 from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True) import tensorflow as tf #创建输入和输出的占位符，数据类型为float x = tf.placeholder(&quot;float&quot;, [None, 784]) y_ = tf.placeholder(&quot;float&quot;, [None, 10]) #创建权值变量w和b #y = xw+b,所以w的维度为[784,10], b的维度为[,10] w = tf.Variable(tf.random_normal([784, 10], name=&quot;weights&quot;)) b = tf.Variable(tf.random_normal([10], name=&quot;bias&quot;)) #softmax回归模型 #tf.multiply(x,y)是x和y的元素级别的相乘；tf.matmul为矩阵相乘 #y = tf.nn.softmax(tf.matmul(x, w)+b) y = tf.matmul(x,w)+b #定义损失函数，使用交叉熵作为损失 #cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=1)) #cross_entropy = -tf.reduce_sum(y_*tf.log(y), reduction_indices=1) cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y) #训练 lr_rate = 0.01 #train_step = tf.train.AdamOptimizer(lr_rate).minimize(cost) train_step = tf.train.GradientDescentOptimizer(lr_rate).minimize(cross_entropy) init= tf.initialize_all_variables() with tf.Session() as sess: sess.run(init) for epoch in range(100000): x_batch, y_batch = mnist.train.next_batch(100) sess.run(train_step, feed_dict={x : x_batch, y_ : y_batch }) #训练精确度， training acc correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(y,1)) acc = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;)) if epoch%1000==0: print(&quot;step : &quot;+str(epoch)+&quot; training accuracy is : &quot;+str(acc.eval(feed_dict={x:x_batch, y_:y_batch}))) #评估 ##比较一下预测值和真实值，如果一致则返回true，否则返回false correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(y,1)) ##计算准确率tf.cast是转换数据格式，如下是转换为float ##计算均值tf.reduce_mean accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;)) print(&quot;accuracy : &quot;+str(sess.run(accuracy, feed_dict={x : mnist.test.images, y_ : mnist.test.labels})))]]></content>
      <categories>
        <category>tensorflow实现XX</category>
      </categories>
      <tags>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SIFT特征提取分析算法]]></title>
    <url>%2F2018%2F04%2F14%2FSIFT%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文链接 SIFT实验楼转载整理 一、SIFT介绍1 简介SIFT 算法是在一幅图片不同的尺度空间上检测图像关键点的局部特征算法。SIFT算法通过关键点进行匹配，检测图片中物体的位置尺度和旋转不变量，使得分类器有良好的效果。该算法的应用范围很广，在图像导航、追踪、动作识别等方面都有较深刻的应用。 2 知识点 卷积模糊概念 高斯卷积模糊 图像金字塔 关键点选取 描述子生成 二、步骤 图像卷积运算 高斯模糊 高斯函数卷积核：高斯函数的 “3delta” 原则(delta为标准差)，当距离中心点的距离大于 “3delta” 之后，其效果可以忽略在。进行高斯核的确定时，仅选用距离中心点小于3delta 的点进行模板选取，模板大小为 “(6delta+1)(6*delta+1)”。 分离高斯模糊：当使用二维模板进行图像处理时损失的图像信息由模板大小决定。模板无法匹配到的点将丢失。经验证二维高斯模糊可以由水平方向上的一维高斯模糊和竖直方向上的一维高斯模糊相加得到，这也称作是高斯函数的分离性。 高斯金字塔 降维采样：对于每层的图进行隔点采样 高斯采样：高斯金字塔的建立与简单的降维采样不同的是：高斯金字塔采样出的每一层实际上是一组数据，而简单降维采样每一层仅仅是一幅图像。 高斯差分金字塔采样：将每一组图片中的相邻两幅图片进行相减，将原高斯金字塔生成新的每组含有N−1幅图像的高斯差分金字塔。 关键点检测 寻找关键点 粗略搜索：找到某一点，将其和相邻的两个尺度空间内的两个相同坐标点及这三个坐标点在同尺度空间相邻的八个一共26个（3×8+2）坐标点进行比较。若该点大于或小于其他所有点，那么这个点可能是我们要寻找的关键点。所判断点的邻域可以理解成为一个三阶魔方的形状。 定位关键点：对DOG金字塔函数使用泰勒展开，带入候选关键点。 去除边缘效应：使用Hessian矩阵计算主曲率，主曲率与矩阵的迹的平方与行列式之比成正比，当矩阵的迹的平方与行列式之比大于某个值时，忽略该点 求关键点方向 求梯度方向直方图：梯度方向直方图的横轴为梯度方向，纵轴为在该方向上的梯度幅值累加值。将邻域中的点的幅值进行分解，将其分解到每隔45度一个横轴方向的坐标中，最终得到一个横轴为八个方向的坐标系。 确定关键点主方向：在直方图中，选取梯度幅度累加值最大的对应方向为该关键点的主方向，若有其他方向的累加值大于主方向累加值的80%时，将该方向认定为该关键点的辅方向。 描述子生成 采样区域 计算直方图描述子生成：将每一个图像块中的方向进行类似之前计算关键点的步骤，将其分解到八个方向上。在一个描述子中有16个图像块，每一个图像块中有 88 维特征值，这样在一个描述子中即可获得128维的描述。 生成描述子的流程解释 在高斯差分金字塔中寻找某一点，该点为其尺度空间间隔为1的邻域中的最大值或者最小值。 将该点的DOG函数用泰勒展开式进行展开并将极值点带入 删除其边缘效应，得到准确的关键点。 求出关键点的梯度分布直方图，将其分解到间隔为45度的梯度方向上，将最大的方向设置为该点的主方向。 在关键点周围选取采样区域，并将坐标系旋转至该点的主方向上。 计算直方图，得出128维特征向量，并进行归一化处理。]]></content>
      <categories>
        <category>图片处理</category>
      </categories>
      <tags>
        <tag>SIFT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三分找极点]]></title>
    <url>%2F2018%2F04%2F14%2F%E4%B8%89%E5%88%86%E6%89%BE%E6%9E%81%E7%82%B9%2F</url>
    <content type="text"><![CDATA[三分搜索概念三分搜索 三分搜索tips 找极大值的时候若左中点比右中点更靠近极大值，right取右边中点；否则left取左边中点（找极小值相反） 找极大值坐标的时候，while循环的判断条件可以设为right-left&gt;4，留出空挡就可以不用判断边界了 三分搜索模板--三分找极点值，二维-- const double EPS = 1e-10; double cal(double x) { // f(x) = -(x-3)^2 + 2; return (x-3.0)*(x-3.0) + 2; } double threeSearch(double low, double high) { while(high-low&gt;EPS) { double mid = low + (high-low)/2; double midmid = mid+(high-mid)/2; if(cal(mid)&gt;cal(midmid)) //找极大值用&gt;, 找极小值用&lt; high = midmid; else low = mid; } return low; } --三分找极值点坐标-- int threeSearch(vector&lt;int&gt; nums) { int left = 0, right = nums.size()-1; //trick：留出空档来就不用判断边界条件了 while(right-left&gt;4){ int mid = left + (right-left)/2; int midmid = mid+(right-mid)/2; if(nums[mid]&gt;nums[midmid]) //极大用“&gt;”，极小用“&lt;” right = midmid-1; else left = mid+1; } int pos = left;//pos为最终目标 for(int i=left;i&lt;right;i++) { if(nums[i]&lt;=nums[i+1]) //极大用&quot;&lt;=&quot;，极小用&quot;&gt;=&quot; pos = i+1; else break; } return pos; } ##实战 题目一个先升序后降序的数组中判断一个数是否存在 解法先三分找极点，然后二分判断是否存在 #include&lt;iostream&gt; #include &lt;vector&gt; using namespace std; //三分找极值点坐标，一维 int threeSearch(vector&lt;int&gt; nums) { int left = 0, right = nums.size()-1; //trick：留出空档来就不用判断边界条件了 while(right-left&gt;4){ int mid = left + (right-left)/2; int midmid = mid+(right-mid)/2; if(nums[mid]&gt;nums[midmid]) //极大用“&gt;”，极小用“&lt;” right = midmid-1; else left = mid+1; } int pos = left;//pos为最终目标 for(int i=left;i&lt;right;i++) { if(nums[i]&lt;=nums[i+1]) //极大用&quot;&lt;=&quot;，极小用&quot;&gt;=&quot; pos = i+1; else break; } return pos; } bool inNums(vector&lt;int&gt;nums, int key) { int index = threeSearch(nums); int left = 0, right = index; //在上升序列中找是否存在 while(left&lt;=right) { int mid = left + (right-left)/2; if(nums[mid]&gt;key) right = mid-1; else if(nums[mid]&lt;key) left = mid+1; else return true; } if(key&gt;nums[index]) return false; //在下降序列中找是否存在 left = index+1, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(nums[mid]&lt;key) right = mid-1; else if(nums[mid]&gt;key) left = mid+1; else return true; } return false; } int main() { int temp[] = {1,2,3,3,3,4,4,3,3,2,1}; vector&lt;int&gt; test(temp, temp+sizeof(temp)/sizeof(int)); cout&lt;&lt;inNums(test, 1)&lt;&lt;endl; return 0; }]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>三分搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相似图片搜索]]></title>
    <url>%2F2018%2F04%2F12%2F%E7%9B%B8%E4%BC%BC%E5%9B%BE%E7%89%87%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[原文链接 相似图片搜索的原理–阮一峰 相似图片搜索的原理(二)–阮一峰 图片搜索方法简述1.感知哈希算法(perceputal hash algorithm) 原理：对每张图片生成一个“指纹”字符串，然后比较不同图片的指纹。结果越相近，就说明图片越相似 步骤： step1: 缩小尺寸，将图片缩小到8x8大小，摒弃图片的细节，只保留结构、明暗等特征 step2: 简化色彩，图片转为64度灰，即所有像素点总共只有64种颜色。(原灰度图每个像素范围为0~255，表示256度灰，那么每个像素值除以4就得到了64度灰) step3: 计算平均值，计算所有64个像素的灰度平均值 step4: 比较像素的灰度，将每个像素的灰度都与平均值比较，大于平均值的记1，不然记0 step5: 计算哈希值，将上一步的比较结果组合构成64位的整数，这就是图片的指纹 step6: 通过计算汉明距离得到图片相似度 代码实现：imghash 优缺点：简单快速，不受图片大小的缩放影响，缺点是图片的内容不能变更。如果在图片上加几个文字，它就认不出来了。所以，它的最佳用途是根据缩略图，找出原图。 2.颜色分布法 原理：任何颜色都是由RGB三原色构成，所以一张图片会有4张直方图（三原色直方图+最后合成的直方图。如果每种原色都可以取256个值，可以将0～255分成四个区：0～63为第0区，64～127为第1区，128～191为第2区，192～255为第3区。这意味着红绿蓝分别有4个区，总共可以构成64种组合（4的3次方），任何一种颜色必然属于这64种组合种的一种，这样就可以统计每一种组合包含的像素数，形成一个长度位64的特征向量。 3.内容特征法 步骤： 将原图转换为1张较小的灰度图像，比如5050像素。（Gray = R\0.299 + G*0.587 + B*0.114） 确定一个阈值，将灰度图片转换为黑白轮廓图片。 核心：如何确定阈值-&gt;“大津法” 假设一张图片共有n个像素，其中灰度值小于阈值的像素为n1个，大于等于的为n2个。则可以计算得到两种像素各自的比重。 w1 = n1 / n ; w2 = n2 / n 假设所有灰度值小于阈值的像素的平均值和标准差为u1和delta1，所有大于等于阈值的像素的平均值和方差为u2和delta2。则类内差异 = w1*（delta1的平方） + w2*(delta2的平方)；类间差异 = w1*w2*(u1-u2)^2。可以证明得到类内差异的最小值等同于得到类间差异的最大值,证明见下图。 用穷举法得到阈值。阈值从灰度的最低值到最高值依次取一遍，带入使得类内差异最小或者类外差异最大的值即为最终的阈值。]]></content>
      <categories>
        <category>图片处理</category>
      </categories>
      <tags>
        <tag>图片搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MTCNN论文笔记]]></title>
    <url>%2F2018%2F04%2F11%2FMTCNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[脸部检测及landmarks标记 背景 论文: Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks 代码地址: Github 作者博客 概况 论文提出了一种深层的级联multi-task框架 分三个阶段的深度卷积网络由粗到细的检测人脸及预测landmark location 论文提出了一种有效的online hard sample mining的策略来提升性能.(在每个mini-batch中选择前向计算误差前70%大的样本用来BP) 方法1.总体框架 2.三步骤 pre：先将图片resize，叠成“金字塔” stage1：采用P-Net获得候选窗口以及bounding box回归向量，然后用估计的bounding box回归向量去校准候选窗口。然后使用非极大值抑制(NMS,non-maximum supression)来合并高度重合的候选窗口。（非极大值抑制：首先对每个窗口按照score（置信度）进行递降排序，取score最大的窗口，然后计算剩下的与最大的窗口之间的IOU，也就是重叠面积，如果大于一定阈值就将框删除，然后一直重复上述步骤直到候选窗口为空） stage2：将所有的候选数据喂给R-Net进一步消除不合适的候选窗口，并且通过bounding box回归及NMS去校准 stage3：与2类似，不同的是这一阶段的目的是输出脸部细节，即五个脸部的landmarks位置 3.CNN结构 将5x5大小的滤波窗口减小到3x3大小的滤波窗口以减少计算 增加深度以更好的提取特征 4.训练 face classification损失函数(2分类，交叉熵损失) bounding box regression损失(计算预测坐标向量和真实坐标向量的欧氏距离) facial landmark localization损失(欧式距离) multi-source，alpha为任务重要性，beta为样本类型索引取值为0或1，样本种类包括{negative(IoU&lt;0.3), positive(IoU&gt;0.65), part face(0.4&lt;IoU&lt;0.65), landmark face}；在计算训练的总体损失的时候，classifier, bounding box regression和landmarks detection的权重是不一样的；训练数据共分为4类，比例为 online hard sample mining,在每个mini-batch中选择前向计算误差前70%大的样本用来BP) 实验结果 online hard sample mining效果 联合检测及校准的效果 检验脸部检测的效果 检验脸部校准的效果]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>mtcnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分查找及其变种]]></title>
    <url>%2F2018%2F04%2F10%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%8F%8A%E5%85%B6%E5%8F%98%E7%A7%8D%2F</url>
    <content type="text"><![CDATA[二分模板int binarySearch(vector&lt;int&gt;nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left+(right-left)/2; if(key ? nums[mid]){ right = mid-1; }else{ left = mid+1; } } //可能还得加判断left，right是否在范围内 return left or right; } 标准二分查找//1.标准二分 int binarySearch_1(vector&lt;int&gt; nums, int key) { int left = 0, right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else if(key&gt;nums[mid]){ left = mid+1; }else{ return mid; } } return -1; } 二分查找变种1.最后一个小于key的元素//2.最后一个小于key的元素 int binarySearch_2(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0) return right; else return -1; } 2.第一个大于key的元素//3.第一个大于key的值 int binarySearch_3(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size()) return left; else return -1; } 3.最后一个小于等于key的元素//4.最后一个小于等于key的值 int binarySearch_4(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } return right; } 4.第一个大于等于key的元素//5.第一个大于等于key的元素 int binarySearch_5(vector&lt;int&gt; nums, int key) { int left = 0,right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } return left; } 5.第一个与key相等的元素//6.第一个与key相等的元素 int binarySearch_6(vector&lt;int&gt;nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size() &amp;&amp; nums[left]==key) return left; return -1; } 6.最后一个与key相等的元素//7.最后一个与key相等的元素 int binarySearch_7(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0 &amp;&amp; nums[right]==key) return right; return -1; } 完整测试代码#include&lt;iostream&gt; #include&lt;vector&gt; using namespace std; //1.标准二分 int binarySearch_1(vector&lt;int&gt; nums, int key) { int left = 0, right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else if(key&gt;nums[mid]){ left = mid+1; }else{ return mid; } } return -1; } //2.最后一个小于key的元素 int binarySearch_2(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0) return right; else return -1; } //3.第一个大于key的值 int binarySearch_3(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size()) return left; else return -1; } //4.最后一个小于等于key的值 int binarySearch_4(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } return right; } //5.第一个大于等于key的元素 int binarySearch_5(vector&lt;int&gt; nums, int key) { int left = 0,right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } return left; } //6.第一个与key相等的元素 int binarySearch_6(vector&lt;int&gt;nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size() &amp;&amp; nums[left]==key) return left; return -1; } //7.最后一个与key相等的元素 int binarySearch_7(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0 &amp;&amp; nums[right]==key) return right; return -1; } void test() { //int test_arr[] = {1,2,2,2,3,4,5};//test1 //int test_arr[] = {2,2,2,4,3};//test2 //int test_arr[] = {1,2,2,2};//test3 //int test_arr[] = {1,2,2,2};//test4 //int test_arr[] = {1,2,3,4};//test5 //int test_arr[] = {1,2,3,5};//test6 int test_arr[] = {1,2,2,5};//test7 vector&lt;int&gt; test_vec(test_arr, test_arr+sizeof(test_arr)/sizeof(int)); cout&lt;&lt;binarySearch_7(test_vec,3)&lt;&lt;endl; } int main() { test(); return 0; }]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FaceNet论文笔记]]></title>
    <url>%2F2018%2F04%2F10%2FFaceNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[背景 论文: FaceNet: A Unified Embedding for Face Recognition and Clustering 代码地址: Github 概况 论文提出了名为FaceNet的框架，该框架学习的是从脸图到欧式距离的映射，这样就可以同图片之间的距离来衡量相似度。相比之前直接用softmax更加高效。 端到端，框架的输出是一个多维度的embedding向量。 损失函数采用的是三联子损失(triplet loss) 文章采用的deepCNN的结构为：1）Zeiler&amp;Fergus加上额外的1x1xN的卷积层,2）inception model 该算法在LFW数据集上实现了99.63%的精确度，在YouTube脸库数据集上实现了95.12%的精确度，准确度比以往算法提升了30% 方法 模型结构 triplet损失函数(三联子) triplet选择 计算argmax和argmin 方案一：每n步产生triplets，使用数据的子集计算argmax, argmin;方案二(论文中采取的方案)：在线生成triplets, 在mini-batch中计算argmax和argmin，论文中一个mini-batch每个人选了40张脸图，并且额外增加了随机的负样本脸图 选择hardest的负样本在实际中会导致训练时候在早起就陷入局部最优，所以论文中采用semi-hard的策略 评估标准 true accept false accept validation rate &amp;&amp; false accept rate 实验结果 不同模型对比 不同图片质量对比 不同embedding维度对比 不同训练集数量对比]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>FaceNet</tag>
      </tags>
  </entry>
</search>
