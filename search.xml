<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[FaceNet论文笔记]]></title>
    <url>%2F2018%2F04%2F10%2FFaceNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[背景 论文链接: FaceNet: A Unified Embedding for Face Recognition and Clustering 代码地址: Github 概况 论文提出了名为FaceNet的框架，该框架学习的是从脸图到欧式距离的映射，这样就可以同图片之间的距离来衡量相似度。相比之前直接用softmax更加高效。 端到端，框架的输出是一个多维度的embedding向量。 损失函数采用的是三联子损失(triplet loss) 文章采用的deepCNN的结构为：1）Zeiler&amp;Fergus加上额外的1x1xN的卷积层,2）inception model 该算法在LFW数据集上实现了99.63%的精确度，在YouTube脸库数据集上实现了95.12%的精确度，准确度比以往算法提升了30% 方法 模型结构 triplet损失函数(三联子) triplet选择 计算argmax和argmin 方案一：每n步产生triplets，使用数据的子集计算argmax, argmin;方案二(论文中采取的方案)：在线生成triplets, 在mini-batch中计算argmax和argmin，论文中一个mini-batch每个人选了40张脸图，并且额外增加了随机的负样本脸图 选择hardest的负样本在实际中会导致训练时候在早起就陷入局部最优，所以论文中采用semi-hard的策略 评估标准 true accept false accept validation rate &amp;&amp; false accept rate 实验结果 不同模型对比 不同图片质量对比 不同embedding维度对比 不同训练集数量对比]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>FaceNet</tag>
      </tags>
  </entry>
</search>
