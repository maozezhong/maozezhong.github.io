<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[人行道检线算法]]></title>
    <url>%2F2018%2F05%2F13%2F%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%2F%E4%BA%BA%E8%A1%8C%E9%81%93%E6%A3%80%E7%BA%BF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景 项目要求，需要检测人行道斑马线，所以寻找相关检线算法，此文记录 方案方案1: Hough检直线 参考road_lane_line_detection 步骤： 过滤颜色（github教程中图片是车辆道路线，分为黄，白，所以只过滤留下黄白就行）；cv.inrange()造掩膜，cv.bitwise_and()去淹膜外背景。 图片灰度化 高斯模糊（平滑）：中心点的像素值为周围点像素值的加权平均，权值按照中心点为远点，其他点按照正太曲线上的位置分配权重 Canny算子进行边缘提取： 高斯滤波图像去噪 计算图像中每个像素的梯度（使用Sobel算子） 非极大值抑制，对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯度方向的点中最大的，是的话就保留。 滞后阈值（双阈值），确定哪些边界是真正的边界。设置一高一低两个阈值，梯度大于高阈值的被认为是真的边界，低于低阈值的则被抛弃，在高阈值和低阈值之间的则看起是否与真的边界相连。 掩膜选取感兴趣的区域 在检测到边缘并掩膜后的图片上Hough检测直线并画线 图片加权（initial_img α + img β + λ， img为加上线后的图片，只有线有颜色，其他全为0，initial_img为原始图片） &gt; - tips： - draw_line中他因为场景需要（高速隔离道，就是一个梯形），把线分成了左右两组;所以想找人行道斑马线的时候，需要把draw_line改一下 - 而且他的region_of_interest为梯度形状的 扩充参考： Canny边缘检测原理 Hough变换原始形式-直线检测 OpenCV-Python 霍夫直线检测-HoughLinesP函数参数 检测结果 官方检测图片 跑斑马线的效果并不好，只能检查出几条线，调整了： min_line_length = 10 -&gt; 200 draw_lines -&gt; draw_lines_1(画出所有的直线) filter_colors里面白色的阈值从200-&gt;185 斑马线原图 检测图片]]></content>
      <categories>
        <category>图片处理</category>
      </categories>
      <tags>
        <tag>人行道检线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yolo系列(3)：yolov3扩充数据集,KITTI数据集转换为voc格式]]></title>
    <url>%2F2018%2F05%2F07%2Fyolo%E7%B3%BB%E5%88%97%2Fyolo%E7%B3%BB%E5%88%97-3-%EF%BC%9Ayolov3%E6%89%A9%E5%85%85%E6%95%B0%E6%8D%AE%E9%9B%86-KITTI%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BD%AC%E6%8D%A2%E4%B8%BAvoc%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[加油 背景 由于项目需求，数据集需要扩展，包括车辆行人等类别，于是找到KITTI数据集，现需将其转换为voc格式 KITTI数据集下载：Object Detection Evaluation 2012 参考博客（所有内容均来自这个博客，只是针对yolo需要的格式进行截取及小改，感谢博主！）:SSD: Single Shot MultiBox Detector 训练KITTI数据集（1） 转换步骤参考博客中下载好数据集，并建立好文件夹后： 1. 转换KITTI类别 我需要的类别是车辆和行人，所以跟博客中一样，未修改。需要注意的是博客中的脚本是直接在原始文件上修改并覆盖的，所以这边我加了几行代码备份了一下原始文件。脚本：modify_annotations_txt.py 2. 转换txt标注信息为xml格式 脚本：txt_to_xml.py 3. 生成训练验证集和测试集列表 博客中生成的txt中只有图片名称，我这边由于yolo格式需要加入了图片绝对路径 脚本：create_train_test_txt.py]]></content>
      <categories>
        <category>yolo系列</category>
      </categories>
      <tags>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode买卖股票系列]]></title>
    <url>%2F2018%2F05%2F06%2F%E5%9F%BA%E7%A1%80_%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%2Fleetcode%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%B3%BB%E5%88%97%2F</url>
    <content type="text"><![CDATA[leetcode买卖股票系列 121. Best Time to Buy and Sell Stock（easy） 122. Best Time to Buy and Sell Stock II（easy） 123. Best Time to Buy and Sell Stock III（hard） 188. Best Time to Buy and Sell Stock IV（hard） 309. Best Time to Buy and Sell Stock with Cooldown（medium） 解答 第121,122题简单，不表 第123题，暴力（自己想出来的，但是1200ms = =！）/ dp / trick class Solution { public: /* 思路： 遍历数组，当前处于i位置的时候，分别求[0~i]买卖一次股票的最大收益和[i+1~end]买卖一次股票的最大收益，求和为i位置的时候的最大收益 复杂度： 时间：O(N^2) 空间：O(1) 爆炸：测试时间1000多ms */ int maxProfit(vector&lt;int&gt;&amp; prices) { if(prices.size()==0) return 0; int res = 0; for(int i=0;i&lt;prices.size();i++) { int left = maxProfitOnce(prices, 0, i); int right = maxProfitOnce(prices, i+1, prices.size()-1); res = max(res, left+right); } return res; } int maxProfitOnce(vector&lt;int&gt;&amp; prices, int start, int end) { int max_ = prices[end]; int res = 0; for(int i=end-1;i&gt;=start;i--) { if(prices[i]&lt;max_) res = max(res, max_-prices[i]); else max_ = prices[i]; } return res; } }; class Solution { public: /* 思路： dp解法，建立一个二维dp数组 dp[k][ii]表示最多k次交易，到prices[ii]为止（不包含prices[ii]）所能获得的最大收益 则dp[k][ii] = max(dp[k][ii-1], prices[ii]-prices[jj]+dp[k-1][jj])其中jj属于[0, ii-1]闭区间，推导可得 dp[k][ii] = max(dp[k][ii-1], prices[ii]+max(dp[k-1][jj]-prices[jj]))其中jj属于[0, ii-1]闭区间 dp[1][ii] = 0 dp[k][1] = 0 复杂度： 时间：O(k*N) 空间：O(k*N) */ int maxProfit(vector&lt;int&gt;&amp; prices) { int res = 0; if(prices.size()==0) return 0; else { int k = 2; vector&lt;vector&lt;int&gt;&gt; dp(k+1, vector&lt;int&gt;(prices.size(), 0)); for(int kk=1;kk&lt;=k;kk++) { int maxTemp = dp[kk-1][0] - prices[0]; for(int ii=1;ii&lt;prices.size();ii++) { dp[kk][ii] = max(dp[kk][ii-1], prices[ii]+maxTemp); //左 res = max(res, dp[k][ii]); maxTemp = max(maxTemp, dp[kk-1][ii]-prices[ii]); //上 } } } return res; } }; class Solution { public: /* 思路： 优化一下dp解法，建立一个一维dp数组 复杂度： 时间：O(k*N) 空间：O(N) */ int maxProfit(vector&lt;int&gt;&amp; prices) { int res = 0; if(prices.size()==0) return 0; else { int k = 2; vector&lt;int&gt; dp(prices.size(), 0); for(int kk=1;kk&lt;=k;kk++) { int maxTemp = dp[0] - prices[0]; for(int ii=1;ii&lt;prices.size();ii++) { int tempTop = dp[ii]; dp[ii] = max(dp[ii-1], prices[ii]+maxTemp); //左 res = max(res, dp[ii]); maxTemp = max(maxTemp, tempTop-prices[ii]); //上 } } } return res; } }; class Solution { public: /* 思路： 初始手上就0块钱,buy1表示我需要向别人借钱来买入这个股票prices[i]，所以我实际上是欠别人buy1块钱，我想让欠的钱约少越好，则需要最大化buy1,因为buy1是负的 -&gt; buy1 = max(buy1, -prices[i]); sell1表示我先在手上有buy1块钱，想以prices[i]卖掉我手上这支股票，卖掉后我剩下sell1块钱，当然也是越大越好，sell1 = max(sell1, buy1+prices[i]); buy2表示我现在手上有sell1块钱，我想买入prices[i]，买入后我手上有buy2块钱，也希望buy2越大越好,buy2 = max(buy2, sell1+prices[i]); sell2表示我现在手上有buy2块钱，想以prices[i]卖掉我手上这支股票，卖掉后我剩下sell2块钱，希望也是sell2越大越好 */ int maxProfit(vector&lt;int&gt;&amp; prices) { if(prices.size()==0) return 0; int buy1 = INT_MIN, sell1 = 0, buy2 = INT_MIN, sell2 = 0; //这么初始化的原因是： //buy1设最小值则我刚开始必买入 //sell1设为0，那么如果卖出后是亏的我就相当于之前不买 //类似设置buy2和sell2 for(int i : prices) { buy1 = max(buy1, -i); sell1 = max(sell1, buy1+i); buy2 = max(buy2, sell1-i); sell2 = max(sell2, buy2+i); } return sell2; } }; 第188题实际上就是第123题dp的解法，不对！dp这样子做会超时！！还得考虑k&gt;=prices.size()/2的时候就转换为问题122的贪心算法！！！ class Solution { public: int maxProfit(int k, vector&lt;int&gt;&amp; prices) { int res = 0; if(k&lt;=0 || prices.size()==0) return 0; if(k&gt;=prices.size()/2) //若次数大于size的一般则相等于无限次数的买入卖出了 { for(int i=0;i&lt;prices.size()-1;i++) { if(prices[i+1]&gt;prices[i]) res += prices[i+1]-prices[i]; } return res; } else { vector&lt;int&gt; dp(prices.size(), 0); for(int kk=1;kk&lt;=k;kk++) { int maxTemp = dp[0] - prices[0]; for(int ii=1;ii&lt;prices.size();ii++) { int temp = dp[ii]; dp[ii] = max(dp[ii-1], prices[ii]+maxTemp); maxTemp = max(maxTemp, temp-prices[ii]); res = max(res,dp[ii]); } } } return res; } };]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[求数组中只无重复的数]]></title>
    <url>%2F2018%2F05%2F05%2F%E5%9F%BA%E7%A1%80_%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%2F%E6%B1%82%E6%95%B0%E7%BB%84%E4%B8%AD%E5%8F%AA%E6%97%A0%E9%87%8D%E5%A4%8D%E7%9A%84%E6%95%B0%2F</url>
    <content type="text"><![CDATA[是真的菜 题目 Given an array of integers, every element appears three times except for one. Find that single one. 代码及思想： class Solution { public: /* 思路： 既然数组中重复数的个数为3，那么只要计算每个bit位的和是否为1就行 比如三个重复数他的某个bit位要么全是1要么全是0，相加的话要么是1+1+1=3，或者是0+0+0=0 然后不重复的那个数该bit位为1的话则总和为4或者1，为0的话其总和为3或者0 总和模3后即不重复的那个数的bit位上的数字 同理推得，如果重复的数的个数为m的话就模m就ok */ int singleNumber1(int A[], int n) { if(n==1) return A[0]; int res = 0; for(int i=0;i&lt;32;i++) { int bits = 0; for(int j=0;j&lt;n;j++) bits += ( (A[j] &amp; (1&lt;&lt;i)) &gt;&gt; i ); res |= ((bits%3) &lt;&lt; i); } return res; } /* 思路2： 用ones记录出现一次的bits数 tows记录出现两次的bits数 threes记录出现三次的bits数 */ int singleNumber1(int A[], int n) { if(n==1) return A[0]; int ones = 0; int twos = 0; int threes = 0; for(int i=0;i&lt;n;i++) { twos |= ones &amp; A[i]; //用&amp;，如果bit位出现两次则为1，不然为0 ones ^= A[i]; threes = twos &amp; ones; //如果twos和ones上的bit位为1则表示出现3次了，所以用&amp; ones &amp;= ~threes; //ones中去除出现三次的bit位 twos &amp;= ~threes; //twos中去除出现三次的bit位 } return ones; } }; 扩展 如果重复的数的次数为2？ 答：直接遍历异或 如果重复的数的次数为m(m&gt;2)？ 答：方法1模m 如果重复的数的次数为2，但是不重复的有2个数？ 答：先遍历异或一遍得到一个数，找到这个数bit位为1的位置，按照这个bit位是否为1将整组数分成两组（不重复的两个数必定分在不同组） 如果重复的数的次数为m(m&gt;2)，但是不重复的有2个数？ 答：用方法1找bits模m为1的bit位，按照这个bit位是否为1将数组分成两组（模m为1表示两个b不重复的数在这个bit位上是不同的）；然后按照方法1分别求不重复的一个数]]></content>
      <tags>
        <tag>single-number</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yolov系列(2)：yolovv3论文笔记]]></title>
    <url>%2F2018%2F05%2F05%2Fyolo%E7%B3%BB%E5%88%97%2Fyolov%E7%B3%BB%E5%88%97-2-%EF%BC%9Ayolov3%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[又是被自己菜醒的一天 背景 论文：YOLOv3：An Incremental Improvement 官网：YOLO: Real-Time Object Detection 官方代码：github 概况 yolov3相对于v2的提升版本 使用dimeansion分簇来得到anchor boxes 每个框预测多标签的类别的时候使用2类的交叉熵作为损失函数 跨图像规模的预测，即隔一段时间resize输入图像的大小 特征提取网络结合了resNet的思想加入了shorcut，有53个卷积层。 方法1. bounding box预测 其中tx，ty，tw，th分别为网络预测层输出的框(的中心横坐标，纵坐标，框的宽度，框的高度，不对应该只是一个网络的输出并不是上述的含义,这个应该是借鉴faster RCNN的，等看了那篇论文再来解释，ok，上述第二图为解释tx,ty,tw,th的由来，截取自YOLOv2 论文笔记)；pw，ph为先验框（anchor boxes）的宽度和高度；cx，cy为预测中心点所在cell相对图片左上角点的偏移；通过上图公式将预测输出最终转换为框的中心点左边bx，by，框的宽度和高度bw，bh 如果一个先验框并不是最好的但是其覆盖ground true超过一定阈值，论文中取的是0.5，则忽略这个预测结果且不计算进损失中 2. 类预测 每个框可能需要预测包含多标签的类，论文中没使用softmax而是用的独立的逻辑斯蒂分类。因为使用softmax的前提假设是一个框中只包含一个类，而现实情况并不是这样的。 3. box的跨尺度预测（针对之前yolo小目标检测不到的诟病） yolov3在三个尺度上做预测 参考的FPN网络，下图引自FPN最新的目标检测算法。每种尺度预测三个box，anchor的设计方式仍然使用聚类的方法得到9 个聚类中心，再将其按照大小均分给3种尺度。尺度1：在基础网络之后添加一些卷积层再输出box信息；尺度2：从尺度1中的倒数第二层的卷积层上采样再与最后一个16×16大小的特征图相加，再次通过多个卷积层后输出box信息，相比尺度1变大两倍；尺度3：与尺度2类似使用了32×32大小的特征图。可以参考网络结构定义文件yolov3.cfg。 把高层特征做2倍上采样（最邻近上采样法），然后将其和对应的前一层特征结合（前一层要经过1 * 1的卷积核才能用，目的是改变channels，应该是要和后一层的channels相同），结合方式就是做像素间的加法。重复迭代该过程，直至生成最精细的特征图。 论文使用kmean获得先验anchor boxes 4. 特征提取 Darknet53,53个卷积层，加上shorcut，下图为其网络结构 5. 训练 训练方法和yolov2相同，多尺度（隔一段epoch改变输入的图片大小，有小有大），BN等 性能及总结 性能 总结 改进后的yolov3能够更好的检测小目标（引入了跨尺度预测），但是相对的中中等及大尺寸的目标效果有所降低 其他都很好哇，666]]></content>
      <categories>
        <category>yolo系列</category>
      </categories>
      <tags>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python运行命令行,sudo]]></title>
    <url>%2F2018%2F05%2F03%2Fpython%2Fpython%E8%BF%90%E8%A1%8C%E5%91%BD%E4%BB%A4%E8%A1%8C-sudo%2F</url>
    <content type="text"><![CDATA[python 命令行交互输入密码 代码cmd = darknet_path + &apos;/darknet&apos; + &apos; detector test &apos; + darknet_path+&apos;/cfg/voc.data &apos; + darknet_path+&apos;/cfg/yolov3-voc.cfg yolov3-voc.weights &apos;+ img_path + &apos; &gt; &apos;+root_path+&apos;/log.txt&apos; print(cmd) sudoPassWd = &apos;*****&apos; #print(cmd) os.system(&apos;echo %s|sudo -S %s&apos; % (sudoPassWd, cmd))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yolo系列(1)续：python调用yolov3并作图（转）]]></title>
    <url>%2F2018%2F05%2F03%2Fyolo%E7%B3%BB%E5%88%97%2Fyolo%E7%B3%BB%E5%88%97(1)%E7%BB%AD%EF%BC%9Apython%E8%B0%83%E7%94%A8yolov3%E5%B9%B6%E4%BD%9C%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[背景 最近项目需要用yolov3检测红绿灯，然后移植到ros上，但是yolo是纯c编写的，所幸作者留了了个python接口。不过接口没有定义画图的方法，所以搜集了这边文章 代码 对darknet.py进行更改，在其中增加showPicResult函数 #-- coding=utf-8 -- from ctypes import * import math import random import cv2 from os import getcwd def sample(probs): s = sum(probs) probs = [a/s for a in probs] r = random.uniform(0, 1) for i in range(len(probs)): r = r - probs[i] if r &lt;= 0: return i return len(probs)-1 def c_array(ctype, values): arr = (ctype*len(values))() arr[:] = values return arr class BOX(Structure): _fields_ = [(&quot;x&quot;, c_float), (&quot;y&quot;, c_float), (&quot;w&quot;, c_float), (&quot;h&quot;, c_float)] class DETECTION(Structure): _fields_ = [(&quot;bbox&quot;, BOX), (&quot;classes&quot;, c_int), (&quot;prob&quot;, POINTER(c_float)), (&quot;mask&quot;, POINTER(c_float)), (&quot;objectness&quot;, c_float), (&quot;sort_class&quot;, c_int)] class IMAGE(Structure): _fields_ = [(&quot;w&quot;, c_int), (&quot;h&quot;, c_int), (&quot;c&quot;, c_int), (&quot;data&quot;, POINTER(c_float))] class METADATA(Structure): _fields_ = [(&quot;classes&quot;, c_int), (&quot;names&quot;, POINTER(c_char_p))] #lib = CDLL(&quot;/home/pjreddie/documents/darknet/libdarknet.so&quot;, RTLD_GLOBAL) wd = getcwd() lib_path = wd + &apos;/libdarknet.so&apos; lib = CDLL(lib_path, RTLD_GLOBAL) lib.network_width.argtypes = [c_void_p] lib.network_width.restype = c_int lib.network_height.argtypes = [c_void_p] lib.network_height.restype = c_int predict = lib.network_predict predict.argtypes = [c_void_p, POINTER(c_float)] predict.restype = POINTER(c_float) set_gpu = lib.cuda_set_device set_gpu.argtypes = [c_int] make_image = lib.make_image make_image.argtypes = [c_int, c_int, c_int] make_image.restype = IMAGE get_network_boxes = lib.get_network_boxes get_network_boxes.argtypes = [c_void_p, c_int, c_int, c_float, c_float, POINTER(c_int), c_int, POINTER(c_int)] get_network_boxes.restype = POINTER(DETECTION) make_network_boxes = lib.make_network_boxes make_network_boxes.argtypes = [c_void_p] make_network_boxes.restype = POINTER(DETECTION) free_detections = lib.free_detections free_detections.argtypes = [POINTER(DETECTION), c_int] free_ptrs = lib.free_ptrs free_ptrs.argtypes = [POINTER(c_void_p), c_int] network_predict = lib.network_predict network_predict.argtypes = [c_void_p, POINTER(c_float)] reset_rnn = lib.reset_rnn reset_rnn.argtypes = [c_void_p] load_net = lib.load_network load_net.argtypes = [c_char_p, c_char_p, c_int] load_net.restype = c_void_p do_nms_obj = lib.do_nms_obj do_nms_obj.argtypes = [POINTER(DETECTION), c_int, c_int, c_float] do_nms_sort = lib.do_nms_sort do_nms_sort.argtypes = [POINTER(DETECTION), c_int, c_int, c_float] free_image = lib.free_image free_image.argtypes = [IMAGE] letterbox_image = lib.letterbox_image letterbox_image.argtypes = [IMAGE, c_int, c_int] letterbox_image.restype = IMAGE load_meta = lib.get_metadata lib.get_metadata.argtypes = [c_char_p] lib.get_metadata.restype = METADATA load_image = lib.load_image_color load_image.argtypes = [c_char_p, c_int, c_int] load_image.restype = IMAGE rgbgr_image = lib.rgbgr_image rgbgr_image.argtypes = [IMAGE] predict_image = lib.network_predict_image predict_image.argtypes = [c_void_p, IMAGE] predict_image.restype = POINTER(c_float) def classify(net, meta, im): out = predict_image(net, im)#得到的是各个类别的概率值 #print(out) res = [] for i in range(meta.classes): res.append((meta.names[i], out[i])) res = sorted(res, key=lambda x: -x[1]) return res def detect(net, meta, image, thresh=.5, hier_thresh=.5, nms=.45): im = load_image(image, 0, 0) num = c_int(0) pnum = pointer(num) predict_image(net, im) dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, None, 0, pnum) num = pnum[0] if (nms): do_nms_obj(dets, num, meta.classes, nms); res = [] for j in range(num): for i in range(meta.classes): if dets[j].prob[i] &gt; 0: b = dets[j].bbox res.append((meta.names[i], dets[j].prob[i], (b.x, b.y, b.w, b.h))) res = sorted(res, key=lambda x: -x[1]) free_image(im) free_detections(dets, num) return res # display the pic after detecting. 2018.04.25 def showPicResult(image, r, out_img=&quot;./predictions.jpg&quot;): img = cv2.imread(image) cv2.imwrite(out_img, img) for i in range(len(r)): x1=r[i][2][0]-r[i][2][2]/2 y1=r[i][2][1]-r[i][2][3]/2 x2=r[i][2][0]+r[i][2][2]/2 y2=r[i][2][1]+r[i][2][3]/2 im = cv2.imread(out_img) cv2.rectangle(im,(int(x1),int(y1)),(int(x2),int(y2)),(0,255,0),3) #This is a method that works well. cv2.imwrite(out_img, im) cv2.imshow(&apos;yolo_image_detector&apos;, cv2.imread(out_img)) cv2.waitKey(1) #cv2.destroyAllWindows() if __name__ == &quot;__main__&quot;: #net = load_net(&quot;cfg/densenet201.cfg&quot;, &quot;/home/pjreddie/trained/densenet201.weights&quot;, 0) #im = load_image(&quot;data/wolf.jpg&quot;, 0, 0) #meta = load_meta(&quot;cfg/imagenet1k.data&quot;) #r = classify(net, meta, im) #print r[:10] wd = getcwd() net = load_net(wd+&quot;/cfg/yolov3-voc.cfg&quot;, wd+&quot;/yolov3-voc.weights&quot;, 0) meta = load_meta(wd+&quot;/cfg/voc.data&quot;) image_path = wd+&quot;/009535.jpg&quot; #im = cv2.imread(image_path) #cv2.imshow(&quot;ori_pic&quot;,im) r = detect(net, meta, image_path) #return [class_name, pro, [x,y,w,h]], [x,y] is center point, [w,h] is width and high of box #r = classify(net, meta, im) #return [[class_name1, pro1],...,[class_name2, pro2]] print(r) showPicResult(image_path, r) 参考 简介yolo在python下对图片的检测及画框 学习笔记：简介yolo在python下识别本地视频]]></content>
      <categories>
        <category>yolo系列</category>
      </categories>
      <tags>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跑tensorflow踩过的坑]]></title>
    <url>%2F2018%2F05%2F03%2Ftensorflow%2F%E8%B7%91tensorflow%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[tensorflow报错锦集 2018年5月3日 Q1: 在自定义损失函数的时候，求tf.sqrt()用到了类型转换tf.bitcast；然后报错LookupError: No gradient defined for operation &#39;loss/Bitcast&#39; (op type: Bitcast)； A1：用tf.to_float转类型试试，实测已经解决 Q2：ValueError: Cannot feed value of shape (485686,) for Tensor &#39;input_y:0&#39;, which has shape &#39;(?, 485686)&#39; A2：维度问题，tf.expand_dims(y, 0)，0为在前面加维度，1为加在第二维，-1为加在最后一维应该可以解决；不对用这个方法还是报错TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(&quot;ExpandDims:0&quot;, shape=(1, 485686), dtype=float64) which was passed to the feed with key Tensor(&quot;input_y:0&quot;, shape=(?, 485686), dtype=float32).，看来得用np.reshape,解决 Q3：InvalidArgumentError (see above for traceback): Nan in summary histogram for: conv-maxpool-3/W_0/grad/hist [[Node: conv-maxpool-3/W_0/grad/hist = HistogramSummary[T=DT_FLOAT, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](conv-maxpool-3/W_0/grad/hist/tag, gradients/conv-maxpool-3/conv_grad/tuple/control_dependency_1)]] A3：问题解答;可能是梯度爆炸，在计算距离的时候可能商为0？在商上面加个很小的值看看；不行，还是会报错。试试数据类型转高精度to_double,同时把学习率给折半了5 e-4，还是不行；把hist写入的那个关了。 Q4：tensorflow加载模型的时候报错：tensorflow.python.framework.errors_impl.DataLossError: Unable to open table file； A4：TensorFlow 模型保存/载入；saver.restore()时填的文件名，因为在saver.save的时候，每个checkpoint会保存三个文件，如my-model-10000.meta, my-model-10000.index, my-model-10000.data-00000-of-00001在import_meta_graph时填的就是meta文件名，我们知道权值都保存在my-model-10000.data-00000-of-00001这个文件中，但是如果在restore方法中填这个文件名，就会报错，应该填的是前缀，这个前缀可以使用tf.train.latest_checkpoint(checkpoint_dir)这个方法获取。 Q5：`ValueError: The name ‘global_step’ refers to an Operation, not a Tensor. Tensor names must be of the form “&lt;op_name&gt;:&lt;output_index&gt;”. A5：.get_operation_by_name(‘’).outputs[0]（亲测可以）或者.get_collection(‘’)没试过 Q6：KeyError: &quot;The name &#39;loss&#39; refers to an Operation not in the graph.&quot;，loss是在scope(“loss”)下面的，重载模型后不知道名字应该是啥，应为loss没命名名字，只是放在scope(“loss”)下面 A6：貌似无解，因为loss不是张量。直接定义调用？]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow保存模型及重载模型]]></title>
    <url>%2F2018%2F05%2F03%2Ftensorflow%2Ftensorflow%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%8F%8A%E9%87%8D%E8%BD%BD%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[tensorflow保存模型及重载模型 保存模型及重载部分模型# -*- coding=utf-8 -*- import tensorflow as tf from tensorflow.python import pywrap_tensorflow #---------------------------------------------保存模型--------------------------------------------- &apos;&apos;&apos; v1= tf.Variable(tf.random_normal([784, 200], stddev=0.35), name=&quot;v1&quot;) v2= tf.Variable(tf.zeros([200]), name=&quot;v2&quot;) #v3= tf.Variable(tf.zeros([100]), name=&quot;v3&quot;) saver = tf.train.Saver() with tf.Session() as sess: init_op = tf.global_variables_initializer() sess.run(init_op) saver.save(sess,&quot;checkpoint/model_test&quot;,global_step=1) &apos;&apos;&apos; #---------------------------------------------重载部分模型--------------------------------------------- v1= tf.Variable(tf.random_normal([784, 200], stddev=0.35), name=&quot;v1&quot;) v2= tf.Variable(tf.zeros([200]), name=&quot;v2&quot;) v3= tf.Variable(tf.zeros([100]), name=&quot;v3&quot;) #saver = tf.train.Saver() #saver1 = tf.train.Saver([v1]) #saver2 = tf.train.Saver([v2]+[v3]) ## 获得保存的模型中的tensor名字 checkpoint_path = &apos;/home/maozezhong/Desktop/bank_competition/cnn-text-classification-tf/checkpoint&apos; ckpt = tf.train.get_checkpoint_state(checkpoint_path) reader = pywrap_tensorflow.NewCheckpointReader(ckpt.model_checkpoint_path) var_to_shape_map = reader.get_variable_to_shape_map() point_name_list = [] for key in var_to_shape_map: point_name_list.append(key) print(point_name_list) ## 若全局变量的名称中包含保存的模型的tensor名称则重载 var_to_restore = [] #需要重载的模型参数的tensor名称 var = tf.global_variables() for val in var: print(val.name) for point in point_name_list: if point in val.name: var_to_restore.append(val) break print(var_to_restore) saver1 = tf.train.Saver(var_to_restore) with tf.Session() as sess: # init_op = tf.global_variables_initializer() # sess.run(init_op) saver1.restore(sess, &quot;checkpoint/model_test-1&quot;) #saver2.restore(sess, &quot;checkpoint/model_test-1&quot;) # saver.save(sess,&quot;checkpoint/model_test&quot;,global_step=1) 参考 tensorflow: 保存和加载模型, 参数；以及使用预训练参数方法 tensorflow 加载部分变量]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorflow模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yolo系列(1)：使用yolov3检测红绿灯]]></title>
    <url>%2F2018%2F04%2F29%2Fyolo%E7%B3%BB%E5%88%97%2Fyolo%E7%B3%BB%E5%88%97(1)%EF%BC%9A%E4%BD%BF%E7%94%A8yolov3%E6%A3%80%E6%B5%8B%E7%BA%A2%E7%BB%BF%E7%81%AF%2F</url>
    <content type="text"><![CDATA[背景 官网：YOLO: Real-Time Object Detection 官方代码：github 非官方代码：github 使用yolov3检测红绿灯机器配置 GPU：GeForce GTX 1060 6GB/PCIe/SSE2 内存：7.7 GiB 环境：unbuntu 16.04 环境配置 显卡驱动安装 CUDA和CUDNN（非必须,我这边跑yolov3的时候没有配置这个）安装 安装darknet及下载yolov3与训练权重 按照官网教程来, darknet安装 ; 权重下载 voc格式数据集制作 voc格式 参考YOLOv2训练自己的数据集（VOC格式）;【YOLO学习】使用YOLO v2训练自己的数据 训练图片格式类似000001.jpg、000002.jpg 按照voc数据集的结构放置图像文件。1）Annotation中主要存放xml文件，每一个xml对应一张图像，并且每个xml中存放的是标记的各个目标的位置和类别信息，命名通常与对应的原始图像一样;2)ImageSets我们只需要用到Main文件夹，这里面存放的是一些文本文件，通常为train.txt、test.txt等，该文本文件里面的内容是需要用来训练或测试的图像的名字;3）JPEGImages文件夹中放我们已按统一规则命名好的原始图像。 --VOC --Annotations --ImageSets --Main --Layout --Segmentation --JPEGImages --SegmentationClass//暂时可有可无 --SegmentationObject //暂时可有可无 将新建的voc文件夹放到scripts/VOCdevkit/目录下，若无VOCdevkit文件夹则新建一个。 用labelImg标注图像,windows版本;linux版本。会自己生成相关标签的xml文件，很好用。 根据自己情况修改/scripts/voc_label.py脚本并运行，将xml文件转换成yolo格式的txt文件。同时会在scripts文件夹下生成labels文件夹。 本次实验采用的是交通信号灯识别公开数据集 Traffic Lights Recognition (TLR) public benchmarks，该数据集有提供相应动GroundTruth，所以不需要自己标注了，但是所提供的标签格式与yolov3要求动有点区别，可以使用preprocess脚本对图像格式以及label格式进行转换。通过generate_train_validation脚本将总的数据集分为训练集和验证集。 修改配置文件 修改/cfg/voc.data文件，class为类别数目，train为训练数据txt所放的位置，valid为validation数据txt所放的位置，names为voc.names所放的位置，backup为模型训练过程中存储模型参数的位置 修改/data/voc.name文件，一行一个类别标签 修改/cfg/yolov3-voc.cfg，用的哪个模型就修改哪个模型的.cfg文件，这边用动是yolov3-voc。1）修改batchsize=64和subdivisions=8,batch_size表示每一个批次用来训练的图片张数，subdivisions表示一个批分成几组导入训练。若出现GPU训练动时候提示memory_out可以修改这两个参数试试;2）filters=75-&gt;filters=27,计算公式为filters=3x(classes数目+5);3）[yolo]子参数下，classes大小改成你的训练数据的类别数目，这边为4，random改成0（关闭多尺度训练，如果显存足够可以置为1） 修改使yolov3在GPU上运行 将makefile中的第一行改成GPU=1 重新make一下 训练以及检测 训练：运行./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74 测试：运行./darknet detector test cfg/voc.data cfg/yolov3-voc.cfg yolov3.weights;yolov3.weights为你训练好的模型权重，之前存在.name文件中设置的backup路径中 扩展1.理解yolo的输出含义（译文）2.批量测试yolo模型效果3. 别的一些训练数据集 常用图像数据集 常用图像数据集 CV Datasets on the web 车辆检测相关数据集 机器学习实践系列之7 - 车辆检测 行人检测 行人检测——Caltech Pedestrian Dataset 数据集的使用 自动驾驶数据集 apollow scape数据集 交通信号灯识别公开数据集 Traffic Lights Recognition (TLR) public benchmarks Traffic-Sign Detection and Classification in the Wild（交通标志） 交通场景数据集(打不开，不知道是不是网络原因) udacity/self-driving-car 自己学习深度学习时，有哪些途径寻找数据集？ 4.训练中遇到的问题 ————————————2018.4.28———————————— Q1： region82和region94都为nan A1：可能是框太小之后就不能识别了 Q2：- darknet已经训练了5000轮差不多，想看下测试效果;在继续训练的情下运行./darknet dector test cfg/voc.data cfg/yolov3-voc.cfg yolov3-voc.wegiths /data/red.jpg的时候报错：CUDA Error: __global__ function call is not configured darknet: ./src/cuda.c:36: check_error: Assertion 0 failed.已放弃 (核心已转储) ; A2： 在命令前面加上sudo Q3：CUDA Error: out of memory darknet: ./src/cuda.c:36: check_error: Assertion `0’ failed. A3：显存不够，降低batchsize 5. 再拓展 ————————————2018.5.13———————————— 在Jetson TX2上部署yolov3,YOLOv3 on Jetson TX2 后续测试发现TX2上摄像头实时检测速率只有3FPS左右，因此后续考虑部署tensorrt 使用tensorrt加速参考:TensorRT 3.0在Jetson TX2部署实战,使用tensorRT后速度能提升到10fps，参考jetson tx2 3fps why?]]></content>
      <categories>
        <category>yolo系列</category>
      </categories>
      <tags>
        <tag>yolo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构造哈弗曼树（转）]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%9F%BA%E7%A1%80_%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%2F%E6%9E%84%E9%80%A0%E5%93%88%E5%BC%97%E6%9B%BC%E6%A0%91%EF%BC%88%E8%BD%AC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[转自哈夫曼树算法及C++实现 代码#include&lt;iostream&gt; #include &lt;iomanip&gt;//这个头文件是声明一些 “流操作符”的 //比较常用的有:setw(int);//设置显示宽度，left//right//设置左右对齐。 setprecision(int);//设置浮点数的精确度。 using namespace std; // 哈夫曼树的结点结构 struct element { int weight; // 权值域 int lchild, rchild, parent; // 该结点的左、右、双亲结点在数组中的下标 }; // 选取权值最小的两个结点 void selectMin(element a[],int n, int &amp;s1, int &amp;s2) { for (int i = 0; i &lt; n; i++) { if (a[i].parent == -1)// 初始化s1,s1的双亲为-1 { s1 = i; break; } } for (int i = 0; i &lt; n; i++)// s1为权值最小的下标 { if (a[i].parent == -1 &amp;&amp; a[s1].weight &gt; a[i].weight) s1 = i; } for (int j = 0; j &lt; n; j++) { if (a[j].parent == -1&amp;&amp;j!=s1)// 初始化s2,s2的双亲为-1 { s2 = j; break; } } for (int j = 0; j &lt; n; j++)// s2为另一个权值最小的结点 { if (a[j].parent == -1 &amp;&amp; a[s2].weight &gt; a[j].weight&amp;&amp;j != s1) s2 = j; } } // 哈夫曼算法 // n个叶子结点的权值保存在数组w中 void HuffmanTree(element huftree[], int w[], int n) { for (int i = 0; i &lt; 2*n-1; i++) // 初始化，所有结点均没有双亲和孩子 { huftree[i].parent = -1; huftree[i].lchild = -1; huftree[i].rchild = -1; } for (int i = 0; i &lt; n; i++) // 构造只有根节点的n棵二叉树 { huftree[i].weight = w[i]; } for (int k = n; k &lt; 2 * n - 1; k++) // n-1次合并 { int i1, i2; selectMin(huftree, k, i1, i2); // 查找权值最小的俩个根节点，下标为i1,i2 // 将i1，i2合并，且i1和i2的双亲为k huftree[i1].parent = k; huftree[i2].parent = k; huftree[k].lchild = i1; huftree[k].rchild = i2; huftree[k].weight = huftree[i1].weight + huftree[i2].weight; } } // 打印哈夫曼树 void print(element hT[],int n) { cout &lt;&lt; &quot;index weight parent lChild rChild&quot; &lt;&lt; endl; cout &lt;&lt; left; // 左对齐输出 for (int i = 0; i &lt; n; ++i) { cout &lt;&lt; setw(5) &lt;&lt; i &lt;&lt; &quot; &quot;; cout &lt;&lt; setw(6) &lt;&lt; hT[i].weight &lt;&lt; &quot; &quot;; cout &lt;&lt; setw(6) &lt;&lt; hT[i].parent &lt;&lt; &quot; &quot;; cout &lt;&lt; setw(6) &lt;&lt; hT[i].lchild &lt;&lt; &quot; &quot;; cout &lt;&lt; setw(6) &lt;&lt; hT[i].rchild &lt;&lt; endl; } } int main() { int x[] = { 5,29,7,8,14,23,3,11 }; // 权值集合 element *hufftree=new element[2*8-1]; // 动态创建数组 HuffmanTree(hufftree, x, 8); print(hufftree,15); system(&quot;pause&quot;); return 0; } ——————————————- 2018年5月1日11:36:09更新 ——————————————- 代码题目//给你一个数组，返回哈弗曼树的头结点 #include&lt;iostream&gt; #include &lt;algorithm&gt; #include &lt;vector&gt; using namespace std; struct TreeNode{ TreeNode* left; TreeNode* right; int val; TreeNode(int value):val(value),left(NULL),right(NULL){}; }; vector&lt;int&gt; pickTwoMin(vector&lt;TreeNode*&gt; nums, vector&lt;bool&gt; &amp;visited) { vector&lt;int&gt; res(2); int i1, i2; for(int i=0;i&lt;nums.size();i++) { if(!visited[i]) { i1 = i; break; } } for(int i=0;i&lt;nums.size();i++) { if(!visited[i] &amp;&amp; nums[i]&lt;nums[i1]) i1 = i; } for(int i=0;i&lt;nums.size();i++) { if(!visited[i]&amp;&amp;i!=i1) { i2 = i; break; } } for(int i=0;i&lt;nums.size();i++) { if(!visited[i] &amp;&amp; i!=i1 &amp;&amp; nums[i]&lt;nums[i2]) i2 = i; } res[0] = i1; res[1] = i2; return res; } TreeNode* getHaffMan(vector&lt;TreeNode*&gt; &amp;nums) { vector&lt;bool&gt; visited(2*nums.size()-1, false); int times = nums.size(); for(int i=0;i&lt;times-1;i++) { vector&lt;int&gt; indexs = pickTwoMin(nums, visited); visited[indexs[0]] = true; visited[indexs[1]] = true; TreeNode* head = new TreeNode(nums[indexs[0]]-&gt;val+nums[indexs[1]]-&gt;val); head-&gt;left = nums[indexs[0]]; head-&gt;right = nums[indexs[1]]; nums.push_back(head); } return nums[nums.size()-1]; } int main() { int n; cin&gt;&gt;n; vector&lt;TreeNode*&gt; nums; for (int i=0;i&lt;n;i++) { int val; cin&gt;&gt;val; nums.push_back(new TreeNode(val)); } TreeNode* h1 = getHaffMan(nums); system(&quot;pause&quot;); return 0; }]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>哈弗曼树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hash表]]></title>
    <url>%2F2018%2F04%2F19%2F%E5%9F%BA%E7%A1%80_%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%2Fhash%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希映射函数/* BKDR Hash Function */ unsigned int BKDR_hash(char *str) { unsigned int seed = 131; // 31 131 1313 13131 131313 etc.. unsigned int hash = 0; while (*str) { hash = hash * seed + (*str++); } return (hash &amp; 0x7FFFFFFF); } 哈希解决冲突开放定址法 线性探测再散列：顺序查看表中下一单元，直到找出一个空单元或查遍全表。 二次探测再散列：冲突发生时，在表的左右进行跳跃式探测，比较灵活 伪随机探测再散列：建立一个伪随机数发生器，（如i=(i+p) % m），并给定一个随机数做起点。 实例：已知哈希表长度m=11，哈希函数为：H（key）= key % 11，则H（47）=3，H（26）=4，H（60）=5，假设下一个关键字为69，则H（69）=3，与47冲突。1）如果用线性探测再散列处理冲突，下一个哈希地址为H1=（3 + 1）% 11 = 4，仍然冲突，再找下一个哈希地址为H2=（3 + 2）% 11 = 5，还是冲突，继续找下一个哈希地址为H3=（3 + 3）% 11 = 6，此时不再冲突，将69填入5号单元。 2）如果用二次探测再散列处理冲突，下一个哈希地址为H1=（3 + 12）% 11 = 4，仍然冲突，再找下一个哈希地址为H2=（3 - 12）% 11 = 2，此时不再冲突，将69填入2号单元。3）如果用伪随机探测再散列处理冲突，且伪随机数序列为：2，5，9，……..，则下一个哈希地址为H1=（3 + 2）% 11 = 5，仍然冲突，再找下一个哈希地址为H2=（3 + 5）% 11 = 8，此时不再冲突，将69填入8号单元。 再哈希法 同时构造多个不同的哈希函数，这种方法不易产生聚集，但增加了计算时间。 链地址法（拉链法） 基本思想是将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。 建立公共溢出区 将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。 hash表代码c++/* 因为类的申明和定义分开来分别在.h和.cpp文件，我这边编译错误，所以放在了一起。 */ //--------simpleHashTable.h------- #pragma once #include &lt;iostream&gt; using namespace std; typedef int KeyType; #define NULLKEY -1 struct Entry{ KeyType _key; int _value; Entry(KeyType key=NULLKEY, int value=0):_key(key),_value(value){} }; class hashTable{ public: hashTable(); //hashTable(int tableSize); ~hashTable(); bool find(const Entry&amp; e); bool insert(const Entry&amp; e); bool remove(const Entry&amp; e); void clear(); Entry&amp; operator[](KeyType key);//重载下标操作；当找不到key对应的Entry时，插入Entry(key,0) int size(); void display(); protected: int hashFunction(KeyType key);//将键值映射到对应地址 void rehash();//调整hashTable大小 bool find(const KeyType&amp; k);//按键值查找 int nextPrime();//p(n) = n^2 - n + 41, n&lt;41, p&lt;1681 private: Entry *_pTable; int _pos;//当前访问元素的位置 int _size; int _capacity; int primeIndex; }; hashTable::hashTable() { _capacity = 3;//初始化hashTable容量为3,便于观察rehash过程 _pTable = new Entry[_capacity]; _size = 0; primeIndex = 1; } //hashTable::hashTable(int tableSize) //{ // //} hashTable::~hashTable() { clear(); } int hashTable::nextPrime() { int p = std::pow(static_cast&lt;float&gt;(primeIndex),2) - primeIndex + 41; primeIndex = primeIndex &lt;&lt; 1; if(primeIndex &gt;= 41){ cout &lt;&lt; &quot;Max capacity reached. exit!&quot; &lt;&lt; endl; exit(-1); } return p; } bool hashTable::find(const Entry&amp; e) { return(find(e._key)); } bool hashTable::find(const KeyType&amp; k) { _pos = hashFunction(k); if(_pTable[_pos]._key==NULLKEY) return false; int lastPos = _pos; while(_pTable[_pos]._key!=k){ if(++_pos%_capacity == lastPos) return false; } return true; } bool hashTable::insert(const Entry&amp; e) { if((_size*1.0)/_capacity&gt;0.75) rehash();//[OK]插入操作前，需要判断hash table是否需要扩容 if(find(e)) return false; _pTable[_pos] = e; ++_size; return true; } bool hashTable::remove(const Entry&amp; e) { if(!find(e)) return false; _pTable[_pos]._key = NULLKEY; --_size; //rehash();//移除操作后，需要判断hash table是否需要缩容 return true; } void hashTable::clear() { delete []_pTable; _size = _capacity = 0; } Entry&amp; hashTable::operator[](KeyType key) { if(!find(key)) insert(Entry(key,0)); return _pTable[_pos]; } int hashTable::size() { return _size; } int hashTable::hashFunction(KeyType key) { return key%_capacity; } void hashTable::display() { cout &lt;&lt; &quot;capacity = &quot; &lt;&lt; _capacity &lt;&lt; &quot;, size = &quot; &lt;&lt; _size &lt;&lt; endl; for(int i=0; i&lt;_capacity; i++){ if(_pTable[i]._key!=NULLKEY) cout &lt;&lt; &quot;key=&quot; &lt;&lt; _pTable[i]._key &lt;&lt; &quot;,value=&quot; &lt;&lt; _pTable[i]._value &lt;&lt; endl; } } void hashTable::rehash() { cout &lt;&lt; &quot;begin rehash...&quot; &lt;&lt; endl; Entry *p = new Entry[_size];//用来暂存原哈希表 for(int i=0; i&lt;_capacity; i++){//i&lt;_size不对；元素散列在容量为_capacity的hashTable中 if(_pTable[i]._key != NULLKEY) *(p+i) = _pTable[i]; } delete []_pTable; int lastSize = _size; _size = 0; _capacity = nextPrime(); _pTable = new Entry[_capacity]; for(int i=0; i&lt;lastSize; i++) insert(*(p+i)); delete []p; } //------testbench.cpp------ #include &lt;iostream&gt; #include &quot;simpleHashTable.h&quot; using namespace std; int main() { hashTable *pTable = new hashTable; cout &lt;&lt; &quot;insert Entry(1,11)...&quot; &lt;&lt; endl; pTable-&gt;insert(Entry(1,11)); pTable-&gt;display(); cout &lt;&lt; &quot;insert Entry(2,22)...&quot; &lt;&lt; endl; pTable-&gt;insert(Entry(2,22)); pTable-&gt;display(); cout &lt;&lt; &quot;insert Entry(3,33)...&quot; &lt;&lt; endl; pTable-&gt;insert(Entry(3,33)); pTable-&gt;display(); cout &lt;&lt; &quot;insert Entry(4,44)...&quot; &lt;&lt; endl; //pTable-&gt;insert(Entry(4,44)); (*pTable)[4]._value = 44;//下标操作，返回值充当左值 pTable-&gt;display(); cout &lt;&lt; endl &lt;&lt; &quot;delete Entry(1,11)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(1,11)); pTable-&gt;display(); cout &lt;&lt; &quot;delete Entry(2,22)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(2,22)); pTable-&gt;display(); cout &lt;&lt; &quot;delete Entry(3,33)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(3,33)); pTable-&gt;display(); cout &lt;&lt; &quot;delete Entry(3,33)...&quot; &lt;&lt; endl; pTable-&gt;remove(Entry(3,33)); pTable-&gt;display(); delete pTable; getchar(); return 0; } c#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;time.h&gt; /*=================hash table start=========================================*/ #define HASH_TABLE_MAX_SIZE 10000 typedef struct HashNode_Struct HashNode; struct HashNode_Struct { char* sKey; int nValue; HashNode* pNext; }; HashNode* hashTable[HASH_TABLE_MAX_SIZE]; //hash table data strcutrue int hash_table_size; //the number of key-value pairs in the hash table! //initialize hash table void hash_table_init() { hash_table_size = 0; memset(hashTable, 0, sizeof(HashNode*) * HASH_TABLE_MAX_SIZE); } //string hash function unsigned int hash_table_hash_str(const char* skey) { const signed char *p = (const signed char*)skey; unsigned int h = *p; if(h) { for(p += 1; *p != &apos;\0&apos;; ++p) h = (h &lt;&lt; 5) - h + *p; //h = h*31+*p } return h; } //insert key-value into hash table void hash_table_insert(const char* skey, int nvalue) { if(hash_table_size &gt;= HASH_TABLE_MAX_SIZE) { printf(&quot;out of hash table memory!\n&quot;); return; } unsigned int pos = hash_table_hash_str(skey) % HASH_TABLE_MAX_SIZE; HashNode* pHead = hashTable[pos]; while(pHead) { if(strcmp(pHead-&gt;sKey, skey) == 0) //strcmp(str1, str2)：1）相等返回0；2）str1&lt;str2返回负数；3）str1&gt;str2返回正数 { printf(&quot;%s already exists!\n&quot;, skey); return ; } pHead = pHead-&gt;pNext; } HashNode* pNewNode = (HashNode*)malloc(sizeof(HashNode)); memset(pNewNode, 0, sizeof(HashNode)); pNewNode-&gt;sKey = (char*)malloc(sizeof(char) * (strlen(skey) + 1)); strcpy(pNewNode-&gt;sKey, skey); pNewNode-&gt;nValue = nvalue; pNewNode-&gt;pNext = hashTable[pos]; hashTable[pos] = pNewNode; hash_table_size++; } //remove key-value from the hash table void hash_table_remove(const char* skey) { unsigned int pos = hash_table_hash_str(skey) % HASH_TABLE_MAX_SIZE; if(hashTable[pos]) { HashNode* pHead = hashTable[pos]; HashNode* pLast = NULL; HashNode* pRemove = NULL; while(pHead) { if(strcmp(skey, pHead-&gt;sKey) == 0) { pRemove = pHead; break; } pLast = pHead; pHead = pHead-&gt;pNext; } if(pRemove) { if(pLast) pLast-&gt;pNext = pRemove-&gt;pNext; else hashTable[pos] = NULL; free(pRemove-&gt;sKey); free(pRemove); } } } //lookup a key in the hash table HashNode* hash_table_lookup(const char* skey) { unsigned int pos = hash_table_hash_str(skey) % HASH_TABLE_MAX_SIZE; if(hashTable[pos]) { HashNode* pHead = hashTable[pos]; while(pHead) { if(strcmp(skey, pHead-&gt;sKey) == 0) return pHead; pHead = pHead-&gt;pNext; } } return NULL; } //print the content in the hash table void hash_table_print() { printf(&quot;===========content of hash table=================\n&quot;); int i; for(i = 0; i &lt; HASH_TABLE_MAX_SIZE; ++i) if(hashTable[i]) { HashNode* pHead = hashTable[i]; printf(&quot;%d=&gt;&quot;, i); while(pHead) { printf(&quot;%s:%d &quot;, pHead-&gt;sKey, pHead-&gt;nValue); pHead = pHead-&gt;pNext; } printf(&quot;\n&quot;); } } //free the memory of the hash table void hash_table_release() { int i; for(i = 0; i &lt; HASH_TABLE_MAX_SIZE; ++i) { if(hashTable[i]) { HashNode* pHead = hashTable[i]; while(pHead) { HashNode* pTemp = pHead; pHead = pHead-&gt;pNext; if(pTemp) { free(pTemp-&gt;sKey); free(pTemp); } } } } } /* ===============================hash table end=========================*/ /* ============================test function ============================*/ #define MAX_STR_LEN 20 #define MIN_STR_LEN 10 void rand_str(char r[]) { int i; int len = MIN_STR_LEN + rand() % (MAX_STR_LEN - MIN_STR_LEN); for(i = 0; i &lt; len - 1; ++i) r[i] = &apos;a&apos; + rand() % ( &apos;z&apos; - &apos;a&apos;); r[len - 1] = &apos;\0&apos;; } int main(int argc, char** argv) { srand(time(NULL)); hash_table_init(); printf(&quot;insert testing.........\n&quot;); int n = 10; const char *key1 = &quot;aaammd&quot;; const char *key2 = &quot;xzzyym&quot;; const char *key3 = &quot;cdcded&quot;; hash_table_insert(key1, 110); hash_table_insert(key2, 220); hash_table_insert(key3, 330); char str[MAX_STR_LEN + 1]; while(n--) { rand_str(str); hash_table_insert(str, n); } hash_table_print(); printf(&quot;\nlookup testing..........\n&quot;); HashNode* pNode = hash_table_lookup(key1); printf(&quot;lookup result:%d\n&quot;, pNode-&gt;nValue); pNode = hash_table_lookup(key2); printf(&quot;lookup result:%d\n&quot;, pNode-&gt;nValue); printf(&quot;\nremove testing..........\n&quot;); printf(&quot;before remove %s:\n&quot;, key3); hash_table_print(); hash_table_remove(key3); printf(&quot;after remove:\n&quot;); hash_table_print(); hash_table_release(); system(&quot;pause&quot;); return 0; } 参考链接 数据结构与算法：hash冲突解决 hash算法的数学原理是什么，如何保证尽可能少的碰撞？ C++简单实现hash table C++模板中声明和定义是否可以分开存放在.h和.cpp文件中 C++模板类头文件和实现文件分离的方法 C++ 中的模板类声明头文件和实现文件分离后，如何能实现正常编译？]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow实现softmax分类]]></title>
    <url>%2F2018%2F04%2F15%2Ftensorflow%2Ftensorflow%E5%AE%9E%E7%8E%B0softmax%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[使用tensorflow实现softmax分类 from tensorflow.examples.tutorials.mnist import input_data mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True) import tensorflow as tf #创建输入和输出的占位符，数据类型为float x = tf.placeholder(&quot;float&quot;, [None, 784]) y_ = tf.placeholder(&quot;float&quot;, [None, 10]) #创建权值变量w和b #y = xw+b,所以w的维度为[784,10], b的维度为[,10] w = tf.Variable(tf.random_normal([784, 10], name=&quot;weights&quot;)) b = tf.Variable(tf.random_normal([10], name=&quot;bias&quot;)) #softmax回归模型 #tf.multiply(x,y)是x和y的元素级别的相乘；tf.matmul为矩阵相乘 #y = tf.nn.softmax(tf.matmul(x, w)+b) y = tf.matmul(x,w)+b #定义损失函数，使用交叉熵作为损失 #cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=1)) #cross_entropy = -tf.reduce_sum(y_*tf.log(y), reduction_indices=1) cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y) #训练 lr_rate = 0.01 #train_step = tf.train.AdamOptimizer(lr_rate).minimize(cost) train_step = tf.train.GradientDescentOptimizer(lr_rate).minimize(cross_entropy) init= tf.initialize_all_variables() with tf.Session() as sess: sess.run(init) for epoch in range(100000): x_batch, y_batch = mnist.train.next_batch(100) sess.run(train_step, feed_dict={x : x_batch, y_ : y_batch }) #训练精确度， training acc correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(y,1)) acc = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;)) if epoch%1000==0: print(&quot;step : &quot;+str(epoch)+&quot; training accuracy is : &quot;+str(acc.eval(feed_dict={x:x_batch, y_:y_batch}))) #评估 ##比较一下预测值和真实值，如果一致则返回true，否则返回false correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(y,1)) ##计算准确率tf.cast是转换数据格式，如下是转换为float ##计算均值tf.reduce_mean accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;)) print(&quot;accuracy : &quot;+str(sess.run(accuracy, feed_dict={x : mnist.test.images, y_ : mnist.test.labels})))]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SIFT特征提取分析算法]]></title>
    <url>%2F2018%2F04%2F14%2F%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%2FSIFT%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%88%86%E6%9E%90%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文链接 SIFT实验楼转载整理 一、SIFT介绍1 简介SIFT 算法是在一幅图片不同的尺度空间上检测图像关键点的局部特征算法。SIFT算法通过关键点进行匹配，检测图片中物体的位置尺度和旋转不变量，使得分类器有良好的效果。该算法的应用范围很广，在图像导航、追踪、动作识别等方面都有较深刻的应用。 2 知识点 卷积模糊概念 高斯卷积模糊 图像金字塔 关键点选取 描述子生成 二、步骤 图像卷积运算 高斯模糊 高斯函数卷积核：高斯函数的 “3delta” 原则(delta为标准差)，当距离中心点的距离大于 “3delta” 之后，其效果可以忽略在。进行高斯核的确定时，仅选用距离中心点小于3delta 的点进行模板选取，模板大小为 “(6delta+1)(6*delta+1)”。 分离高斯模糊：当使用二维模板进行图像处理时损失的图像信息由模板大小决定。模板无法匹配到的点将丢失。经验证二维高斯模糊可以由水平方向上的一维高斯模糊和竖直方向上的一维高斯模糊相加得到，这也称作是高斯函数的分离性。 高斯金字塔 降维采样：对于每层的图进行隔点采样 高斯采样：高斯金字塔的建立与简单的降维采样不同的是：高斯金字塔采样出的每一层实际上是一组数据，而简单降维采样每一层仅仅是一幅图像。 高斯差分金字塔采样：将每一组图片中的相邻两幅图片进行相减，将原高斯金字塔生成新的每组含有N−1幅图像的高斯差分金字塔。 关键点检测 寻找关键点 粗略搜索：找到某一点，将其和相邻的两个尺度空间内的两个相同坐标点及这三个坐标点在同尺度空间相邻的八个一共26个（3×8+2）坐标点进行比较。若该点大于或小于其他所有点，那么这个点可能是我们要寻找的关键点。所判断点的邻域可以理解成为一个三阶魔方的形状。 定位关键点：对DOG金字塔函数使用泰勒展开，带入候选关键点。 去除边缘效应：使用Hessian矩阵计算主曲率，主曲率与矩阵的迹的平方与行列式之比成正比，当矩阵的迹的平方与行列式之比大于某个值时，忽略该点 求关键点方向 求梯度方向直方图：梯度方向直方图的横轴为梯度方向，纵轴为在该方向上的梯度幅值累加值。将邻域中的点的幅值进行分解，将其分解到每隔45度一个横轴方向的坐标中，最终得到一个横轴为八个方向的坐标系。 确定关键点主方向：在直方图中，选取梯度幅度累加值最大的对应方向为该关键点的主方向，若有其他方向的累加值大于主方向累加值的80%时，将该方向认定为该关键点的辅方向。 描述子生成 采样区域 计算直方图描述子生成：将每一个图像块中的方向进行类似之前计算关键点的步骤，将其分解到八个方向上。在一个描述子中有16个图像块，每一个图像块中有 88 维特征值，这样在一个描述子中即可获得128维的描述。 生成描述子的流程解释 在高斯差分金字塔中寻找某一点，该点为其尺度空间间隔为1的邻域中的最大值或者最小值。 将该点的DOG函数用泰勒展开式进行展开并将极值点带入 删除其边缘效应，得到准确的关键点。 求出关键点的梯度分布直方图，将其分解到间隔为45度的梯度方向上，将最大的方向设置为该点的主方向。 在关键点周围选取采样区域，并将坐标系旋转至该点的主方向上。 计算直方图，得出128维特征向量，并进行归一化处理。]]></content>
      <categories>
        <category>图片处理</category>
      </categories>
      <tags>
        <tag>SIFT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三分找极点]]></title>
    <url>%2F2018%2F04%2F14%2F%E5%9F%BA%E7%A1%80_%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%2F%E4%B8%89%E5%88%86%E6%89%BE%E6%9E%81%E7%82%B9%2F</url>
    <content type="text"><![CDATA[三分搜索概念三分搜索 三分搜索tips 找极大值的时候若左中点比右中点更靠近极大值，right取右边中点；否则left取左边中点（找极小值相反） 找极大值坐标的时候，while循环的判断条件可以设为right-left&gt;4，留出空挡就可以不用判断边界了 三分搜索模板--三分找极点值，二维-- const double EPS = 1e-10; double cal(double x) { // f(x) = -(x-3)^2 + 2; return (x-3.0)*(x-3.0) + 2; } double threeSearch(double low, double high) { while(high-low&gt;EPS) { double mid = low + (high-low)/2; double midmid = mid+(high-mid)/2; if(cal(mid)&gt;cal(midmid)) //找极大值用&gt;, 找极小值用&lt; high = midmid; else low = mid; } return low; } --三分找极值点坐标-- int threeSearch(vector&lt;int&gt; nums) { int left = 0, right = nums.size()-1; //trick：留出空档来就不用判断边界条件了 while(right-left&gt;4){ int mid = left + (right-left)/2; int midmid = mid+(right-mid)/2; if(nums[mid]&gt;nums[midmid]) //极大用“&gt;”，极小用“&lt;” right = midmid-1; else left = mid+1; } int pos = left;//pos为最终目标 for(int i=left;i&lt;right;i++) { if(nums[i]&lt;=nums[i+1]) //极大用&quot;&lt;=&quot;，极小用&quot;&gt;=&quot; pos = i+1; else break; } return pos; } ##实战 题目一个先升序后降序的数组中判断一个数是否存在 解法先三分找极点，然后二分判断是否存在 #include&lt;iostream&gt; #include &lt;vector&gt; using namespace std; //三分找极值点坐标，一维 int threeSearch(vector&lt;int&gt; nums) { int left = 0, right = nums.size()-1; //trick：留出空档来就不用判断边界条件了 while(right-left&gt;4){ int mid = left + (right-left)/2; int midmid = mid+(right-mid)/2; if(nums[mid]&gt;nums[midmid]) //极大用“&gt;”，极小用“&lt;” right = midmid-1; else left = mid+1; } int pos = left;//pos为最终目标 for(int i=left;i&lt;right;i++) { if(nums[i]&lt;=nums[i+1]) //极大用&quot;&lt;=&quot;，极小用&quot;&gt;=&quot; pos = i+1; else break; } return pos; } bool inNums(vector&lt;int&gt;nums, int key) { int index = threeSearch(nums); int left = 0, right = index; //在上升序列中找是否存在 while(left&lt;=right) { int mid = left + (right-left)/2; if(nums[mid]&gt;key) right = mid-1; else if(nums[mid]&lt;key) left = mid+1; else return true; } if(key&gt;nums[index]) return false; //在下降序列中找是否存在 left = index+1, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(nums[mid]&lt;key) right = mid-1; else if(nums[mid]&gt;key) left = mid+1; else return true; } return false; } int main() { int temp[] = {1,2,3,3,3,4,4,3,3,2,1}; vector&lt;int&gt; test(temp, temp+sizeof(temp)/sizeof(int)); cout&lt;&lt;inNums(test, 1)&lt;&lt;endl; return 0; }]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>三分搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相似图片搜索]]></title>
    <url>%2F2018%2F04%2F12%2F%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%2F%E7%9B%B8%E4%BC%BC%E5%9B%BE%E7%89%87%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[原文链接 相似图片搜索的原理–阮一峰 相似图片搜索的原理(二)–阮一峰 图片搜索方法简述1.感知哈希算法(perceputal hash algorithm) 原理：对每张图片生成一个“指纹”字符串，然后比较不同图片的指纹。结果越相近，就说明图片越相似 步骤： step1: 缩小尺寸，将图片缩小到8x8大小，摒弃图片的细节，只保留结构、明暗等特征 step2: 简化色彩，图片转为64度灰，即所有像素点总共只有64种颜色。(原灰度图每个像素范围为0~255，表示256度灰，那么每个像素值除以4就得到了64度灰) step3: 计算平均值，计算所有64个像素的灰度平均值 step4: 比较像素的灰度，将每个像素的灰度都与平均值比较，大于平均值的记1，不然记0 step5: 计算哈希值，将上一步的比较结果组合构成64位的整数，这就是图片的指纹 step6: 通过计算汉明距离得到图片相似度 代码实现：imghash 优缺点：简单快速，不受图片大小的缩放影响，缺点是图片的内容不能变更。如果在图片上加几个文字，它就认不出来了。所以，它的最佳用途是根据缩略图，找出原图。 2.颜色分布法 原理：任何颜色都是由RGB三原色构成，所以一张图片会有4张直方图（三原色直方图+最后合成的直方图。如果每种原色都可以取256个值，可以将0～255分成四个区：0～63为第0区，64～127为第1区，128～191为第2区，192～255为第3区。这意味着红绿蓝分别有4个区，总共可以构成64种组合（4的3次方），任何一种颜色必然属于这64种组合种的一种，这样就可以统计每一种组合包含的像素数，形成一个长度位64的特征向量。 3.内容特征法 步骤： 将原图转换为1张较小的灰度图像，比如5050像素。（Gray = R\0.299 + G*0.587 + B*0.114） 确定一个阈值，将灰度图片转换为黑白轮廓图片。 核心：如何确定阈值-&gt;“大津法” 假设一张图片共有n个像素，其中灰度值小于阈值的像素为n1个，大于等于的为n2个。则可以计算得到两种像素各自的比重。 w1 = n1 / n ; w2 = n2 / n 假设所有灰度值小于阈值的像素的平均值和标准差为u1和delta1，所有大于等于阈值的像素的平均值和方差为u2和delta2。则类内差异 = w1*（delta1的平方） + w2*(delta2的平方)；类间差异 = w1*w2*(u1-u2)^2。可以证明得到类内差异的最小值等同于得到类间差异的最大值,证明见下图。 用穷举法得到阈值。阈值从灰度的最低值到最高值依次取一遍，带入使得类内差异最小或者类外差异最大的值即为最终的阈值。]]></content>
      <categories>
        <category>图片处理</category>
      </categories>
      <tags>
        <tag>图片搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MTCNN论文笔记]]></title>
    <url>%2F2018%2F04%2F11%2Fpaper%2FMTCNN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[脸部检测及landmarks标记 背景 论文: Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks 代码地址: Github 作者博客 概况 论文提出了一种深层的级联multi-task框架 分三个阶段的深度卷积网络由粗到细的检测人脸及预测landmark location 论文提出了一种有效的online hard sample mining的策略来提升性能.(在每个mini-batch中选择前向计算误差前70%大的样本用来BP) 方法1.总体框架 2.三步骤 pre：先将图片resize，叠成“金字塔” stage1：采用P-Net获得候选窗口以及bounding box回归向量，然后用估计的bounding box回归向量去校准候选窗口。然后使用非极大值抑制(NMS,non-maximum supression)来合并高度重合的候选窗口。（非极大值抑制：首先对每个窗口按照score（置信度）进行递降排序，取score最大的窗口，然后计算剩下的与最大的窗口之间的IOU，也就是重叠面积，如果大于一定阈值就将框删除，然后一直重复上述步骤直到候选窗口为空） stage2：将所有的候选数据喂给R-Net进一步消除不合适的候选窗口，并且通过bounding box回归及NMS去校准 stage3：与2类似，不同的是这一阶段的目的是输出脸部细节，即五个脸部的landmarks位置 3.CNN结构 将5x5大小的滤波窗口减小到3x3大小的滤波窗口以减少计算 增加深度以更好的提取特征 4.训练 face classification损失函数(2分类，交叉熵损失) bounding box regression损失(计算预测坐标向量和真实坐标向量的欧氏距离) facial landmark localization损失(欧式距离) multi-source，alpha为任务重要性，beta为样本类型索引取值为0或1，样本种类包括{negative(IoU&lt;0.3), positive(IoU&gt;0.65), part face(0.4&lt;IoU&lt;0.65), landmark face}；在计算训练的总体损失的时候，classifier, bounding box regression和landmarks detection的权重是不一样的；训练数据共分为4类，比例为 online hard sample mining,在每个mini-batch中选择前向计算误差前70%大的样本用来BP) 实验结果 online hard sample mining效果 联合检测及校准的效果 检验脸部检测的效果 检验脸部校准的效果]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>mtcnn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分查找及其变种]]></title>
    <url>%2F2018%2F04%2F10%2F%E5%9F%BA%E7%A1%80_%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%8F%8A%E5%85%B6%E5%8F%98%E7%A7%8D%2F</url>
    <content type="text"><![CDATA[二分模板int binarySearch(vector&lt;int&gt;nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left+(right-left)/2; if(key ? nums[mid]){ right = mid-1; }else{ left = mid+1; } } //可能还得加判断left，right是否在范围内 return left or right; } 标准二分查找//1.标准二分 int binarySearch_1(vector&lt;int&gt; nums, int key) { int left = 0, right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else if(key&gt;nums[mid]){ left = mid+1; }else{ return mid; } } return -1; } 二分查找变种1.最后一个小于key的元素//2.最后一个小于key的元素 int binarySearch_2(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0) return right; else return -1; } 2.第一个大于key的元素//3.第一个大于key的值 int binarySearch_3(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size()) return left; else return -1; } 3.最后一个小于等于key的元素//4.最后一个小于等于key的值 int binarySearch_4(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } return right; } 4.第一个大于等于key的元素//5.第一个大于等于key的元素 int binarySearch_5(vector&lt;int&gt; nums, int key) { int left = 0,right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } return left; } 5.第一个与key相等的元素//6.第一个与key相等的元素 int binarySearch_6(vector&lt;int&gt;nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size() &amp;&amp; nums[left]==key) return left; return -1; } 6.最后一个与key相等的元素//7.最后一个与key相等的元素 int binarySearch_7(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0 &amp;&amp; nums[right]==key) return right; return -1; } 完整测试代码#include&lt;iostream&gt; #include&lt;vector&gt; using namespace std; //1.标准二分 int binarySearch_1(vector&lt;int&gt; nums, int key) { int left = 0, right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else if(key&gt;nums[mid]){ left = mid+1; }else{ return mid; } } return -1; } //2.最后一个小于key的元素 int binarySearch_2(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0) return right; else return -1; } //3.第一个大于key的值 int binarySearch_3(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size()) return left; else return -1; } //4.最后一个小于等于key的值 int binarySearch_4(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } return right; } //5.第一个大于等于key的元素 int binarySearch_5(vector&lt;int&gt; nums, int key) { int left = 0,right=nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } return left; } //6.第一个与key相等的元素 int binarySearch_6(vector&lt;int&gt;nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;=nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(left&lt;nums.size() &amp;&amp; nums[left]==key) return left; return -1; } //7.最后一个与key相等的元素 int binarySearch_7(vector&lt;int&gt; nums, int key) { int left = 0, right = nums.size()-1; while(left&lt;=right) { int mid = left + (right-left)/2; if(key&lt;nums[mid]){ right = mid-1; }else{ left = mid+1; } } if(right&gt;=0 &amp;&amp; nums[right]==key) return right; return -1; } void test() { //int test_arr[] = {1,2,2,2,3,4,5};//test1 //int test_arr[] = {2,2,2,4,3};//test2 //int test_arr[] = {1,2,2,2};//test3 //int test_arr[] = {1,2,2,2};//test4 //int test_arr[] = {1,2,3,4};//test5 //int test_arr[] = {1,2,3,5};//test6 int test_arr[] = {1,2,2,5};//test7 vector&lt;int&gt; test_vec(test_arr, test_arr+sizeof(test_arr)/sizeof(int)); cout&lt;&lt;binarySearch_7(test_vec,3)&lt;&lt;endl; } int main() { test(); return 0; }]]></content>
      <categories>
        <category>基础/经典算法</category>
      </categories>
      <tags>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FaceNet论文笔记]]></title>
    <url>%2F2018%2F04%2F10%2Fpaper%2FFaceNet%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[背景 论文: FaceNet: A Unified Embedding for Face Recognition and Clustering 代码地址: Github 概况 论文提出了名为FaceNet的框架，该框架学习的是从脸图到欧式距离的映射，这样就可以同图片之间的距离来衡量相似度。相比之前直接用softmax更加高效。 端到端，框架的输出是一个多维度的embedding向量。 损失函数采用的是三联子损失(triplet loss) 文章采用的deepCNN的结构为：1）Zeiler&amp;Fergus加上额外的1x1xN的卷积层,2）inception model 该算法在LFW数据集上实现了99.63%的精确度，在YouTube脸库数据集上实现了95.12%的精确度，准确度比以往算法提升了30% 方法 模型结构 triplet损失函数(三联子) - triplet选择 - 计算argmax和argmin - 方案一：每n步产生triplets，使用数据的子集计算argmax, argmin;方案二(论文中采取的方案)：在线生成triplets, 在mini-batch中计算argmax和argmin，论文中一个mini-batch每个人选了40张脸图，并且额外增加了随机的负样本脸图 - 选择hardest的负样本在实际中会导致训练时候在早起就陷入局部最优，所以论文中采用semi-hard的策略 - 评估标准 - true accept - false accept - validation rate &amp;&amp; false accept rate ## 实验结果- 不同模型对比- 不同图片质量对比- 不同embedding维度对比- 不同训练集数量对比]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>FaceNet</tag>
      </tags>
  </entry>
</search>
